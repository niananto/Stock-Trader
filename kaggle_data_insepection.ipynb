{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## install required packages\n",
    "# !pip install swig\n",
    "# !pip install wrds\n",
    "# !pip install pyportfolioopt\n",
    "# ## install finrl library\n",
    "# !pip install -q condacolab\n",
    "# import condacolab\n",
    "# condacolab.install()\n",
    "# !apt-get update -y -qq && apt-get install -y -qq cmake libopenmpi-dev python3-dev zlib1g-dev libgl1-mesa-glx swig\n",
    "# !pip install git+https://github.com/skazgor/FinRL.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os \n",
    "import sys\n",
    "\n",
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['prices_2009.json', 'prices_2010.json', 'prices_2011.json', 'prices_2012.json', 'prices_2013.json', 'prices_2014.json', 'prices_2015.json', 'prices_2016.json', 'prices_2017.json', 'prices_2018.json', 'prices_2019.json', 'prices_2020.json', 'prices_2021.json', 'prices_2022.json']\n"
     ]
    }
   ],
   "source": [
    "dir = os.path.join('dataset', 'kaggle-dse')\n",
    "\n",
    "files = os.listdir(dir)\n",
    "files.sort()\n",
    "files = [f for f in files if f not in ['securities.json', 'prices_2008.json']]\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load all the json files\n",
    "data = []\n",
    "for f in files:\n",
    "    with open(os.path.join(dir, f)) as file:\n",
    "        data.append(json.load(file))\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to pandas dataframe\n",
    "dfs = []\n",
    "for i in range(1,len(data)):\n",
    "    dfs.append(pd.DataFrame(data[i]))\n",
    "df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1612197, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>trading_code</th>\n",
       "      <th>last_traded_price</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>opening_price</th>\n",
       "      <th>closing_price</th>\n",
       "      <th>yesterdays_closing_price</th>\n",
       "      <th>trade</th>\n",
       "      <th>value_mn</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-12-30 00:00:00</td>\n",
       "      <td>1JANATAMF</td>\n",
       "      <td>12.9</td>\n",
       "      <td>13.9</td>\n",
       "      <td>12.3</td>\n",
       "      <td>12.3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4708</td>\n",
       "      <td>124.8680</td>\n",
       "      <td>9623500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-12-29 00:00:00</td>\n",
       "      <td>1JANATAMF</td>\n",
       "      <td>11.8</td>\n",
       "      <td>12.3</td>\n",
       "      <td>11.2</td>\n",
       "      <td>11.7</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>1680</td>\n",
       "      <td>46.8126</td>\n",
       "      <td>3987000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-12-28 00:00:00</td>\n",
       "      <td>1JANATAMF</td>\n",
       "      <td>11.3</td>\n",
       "      <td>11.7</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>11.2</td>\n",
       "      <td>1077</td>\n",
       "      <td>19.3689</td>\n",
       "      <td>1698500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-12-27 00:00:00</td>\n",
       "      <td>1JANATAMF</td>\n",
       "      <td>11.3</td>\n",
       "      <td>11.5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>11.2</td>\n",
       "      <td>11.4</td>\n",
       "      <td>932</td>\n",
       "      <td>13.9884</td>\n",
       "      <td>1249000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-12-26 00:00:00</td>\n",
       "      <td>1JANATAMF</td>\n",
       "      <td>11.6</td>\n",
       "      <td>11.8</td>\n",
       "      <td>11.2</td>\n",
       "      <td>11.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>11.5</td>\n",
       "      <td>1671</td>\n",
       "      <td>31.8171</td>\n",
       "      <td>2746500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date trading_code  last_traded_price  high   low  \\\n",
       "0  2010-12-30 00:00:00    1JANATAMF               12.9  13.9  12.3   \n",
       "1  2010-12-29 00:00:00    1JANATAMF               11.8  12.3  11.2   \n",
       "2  2010-12-28 00:00:00    1JANATAMF               11.3  11.7  11.0   \n",
       "3  2010-12-27 00:00:00    1JANATAMF               11.3  11.5  11.0   \n",
       "4  2010-12-26 00:00:00    1JANATAMF               11.6  11.8  11.2   \n",
       "\n",
       "   opening_price  closing_price  yesterdays_closing_price  trade  value_mn  \\\n",
       "0           12.3           13.0                      12.0   4708  124.8680   \n",
       "1           11.7           12.0                      11.3   1680   46.8126   \n",
       "2           11.0           11.3                      11.2   1077   19.3689   \n",
       "3           11.5           11.2                      11.4    932   13.9884   \n",
       "4           11.6           11.4                      11.5   1671   31.8171   \n",
       "\n",
       "    volume  \n",
       "0  9623500  \n",
       "1  3987000  \n",
       "2  1698500  \n",
       "3  1249000  \n",
       "4  2746500  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trading_code\n",
       "GP            3090\n",
       "SANDHANINS    3090\n",
       "ICBIBANK      3090\n",
       "SAMORITA      3090\n",
       "IDLC          3090\n",
       "              ... \n",
       "TB2Y1024        40\n",
       "GIB             31\n",
       "TB5Y1127        11\n",
       "IICICL          11\n",
       "ICICL            9\n",
       "Name: count, Length: 954, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the unique values in the column\n",
    "df = df.drop_duplicates(subset=['date', 'trading_code'])\n",
    "df['trading_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_companies = [\n",
    "    \"GP\",\n",
    "    \"BATBC\",\n",
    "    \"SQURPHARMA\",\n",
    "    \"RENATA\",\n",
    "    \"BEXIMCO\",\n",
    "    \"BERGERPBL\",\n",
    "    \"MARICO\",\n",
    "    \"BRACBANK\",\n",
    "    \"BXPHARMA\",\n",
    "    \"ISLAMIBANK\",\n",
    "    \"DUTCHBANGL\",\n",
    "    \"EBL\",\n",
    "    \"POWERGRID\",\n",
    "    \"SUMITPOWER\",\n",
    "    \"OLYMPIC\",\n",
    "    \"PUBALIBANK\",\n",
    "    \"CITYBANK\",\n",
    "    \"ALARABANK\",\n",
    "    \"PRIMEBANK\",\n",
    "    \"IFIC\",\n",
    "    \"RECKITTBEN\",\n",
    "    \"NBL\",\n",
    "    \"BSRMSTEEL\",\n",
    "    \"BANKASIA\",\n",
    "    \"SHAHJABANK\",\n",
    "    \"MPETROLEUM\",\n",
    "    \"LINDEBD\",\n",
    "    \"BSC\",\n",
    "    \"JAMUNAOIL\",\n",
    "    \"PADMAOIL\",\n",
    "]\n",
    "\n",
    "len(top_companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2010-12-30 00:00:00    30\n",
       "2018-07-17 00:00:00    30\n",
       "2018-06-05 00:00:00    30\n",
       "2018-06-04 00:00:00    30\n",
       "2018-06-03 00:00:00    30\n",
       "                       ..\n",
       "2014-08-24 00:00:00    30\n",
       "2014-08-21 00:00:00    30\n",
       "2014-08-20 00:00:00    30\n",
       "2014-08-19 00:00:00    30\n",
       "2022-01-02 00:00:00    30\n",
       "Name: count, Length: 3090, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['trading_code'].isin(top_companies)]\n",
    "\n",
    "df['date'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trading_code\n",
       "ALARABANK     3090\n",
       "BANKASIA      3090\n",
       "SQURPHARMA    3090\n",
       "SHAHJABANK    3090\n",
       "RENATA        3090\n",
       "RECKITTBEN    3090\n",
       "PUBALIBANK    3090\n",
       "PRIMEBANK     3090\n",
       "POWERGRID     3090\n",
       "PADMAOIL      3090\n",
       "OLYMPIC       3090\n",
       "NBL           3090\n",
       "MPETROLEUM    3090\n",
       "MARICO        3090\n",
       "LINDEBD       3090\n",
       "JAMUNAOIL     3090\n",
       "ISLAMIBANK    3090\n",
       "IFIC          3090\n",
       "GP            3090\n",
       "EBL           3090\n",
       "DUTCHBANGL    3090\n",
       "CITYBANK      3090\n",
       "BXPHARMA      3090\n",
       "BSRMSTEEL     3090\n",
       "BSC           3090\n",
       "BRACBANK      3090\n",
       "BEXIMCO       3090\n",
       "BERGERPBL     3090\n",
       "BATBC         3090\n",
       "SUMITPOWER    3090\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['trading_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# per year minimum number of trading days\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "\n",
    "# Create a new column 'year_month' for plotting\n",
    "df['year_month'] = df['year'].astype(str) + '-' + df['month'].astype(str)\n",
    "\n",
    "plt.figure(figsize=(25, 5))\n",
    "sns.countplot(x='year_month', data=df, order=sorted(df['year_month'].unique()))\n",
    "plt.xticks(rotation=90)  # Rotate x-axis labels for better visibility\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date                           0\n",
      "trading_code                   0\n",
      "last_traded_price           1469\n",
      "high                        1469\n",
      "low                         1469\n",
      "opening_price                522\n",
      "closing_price                 29\n",
      "yesterdays_closing_price       0\n",
      "trade                       1472\n",
      "value_mn                    1493\n",
      "volume                      1472\n",
      "year                           0\n",
      "month                          0\n",
      "year_month                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# print the zero count of each column\n",
    "zero_counts = df.apply(lambda x: (x==0).sum())\n",
    "print(zero_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date                           0\n",
      "trading_code                   0\n",
      "last_traded_price           1469\n",
      "high                         312\n",
      "low                          312\n",
      "opening_price                 17\n",
      "closing_price                  0\n",
      "yesterdays_closing_price       0\n",
      "trade                       1472\n",
      "value_mn                    1493\n",
      "volume                      1472\n",
      "year                           0\n",
      "month                          0\n",
      "year_month                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean values of each month for the columns high, low, opening, and closing\n",
    "# mean_values = df.groupby(['year', 'month', 'trading_code'])[['high', 'low', 'opening', 'closing']].mean()\n",
    "# Replace the zero values with the mean values\n",
    "new_df = df.copy()\n",
    "new_df[['high', 'low', 'opening_price', 'closing_price']] = \\\n",
    "        new_df.groupby(['year', 'month', 'trading_code'])[['high', 'low', 'opening_price', 'closing_price']].transform(lambda x: x.replace(0, x.mean()))\n",
    "\n",
    "# Verify the changes\n",
    "# print the zero count of each column\n",
    "zero_counts = new_df.apply(lambda x: (x==0).sum())\n",
    "print(zero_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date                           0\n",
      "trading_code                   0\n",
      "last_traded_price           1469\n",
      "high                           0\n",
      "low                            0\n",
      "opening_price                  0\n",
      "closing_price                  0\n",
      "yesterdays_closing_price       0\n",
      "trade                       1472\n",
      "value_mn                    1493\n",
      "volume                      1472\n",
      "year                           0\n",
      "month                          0\n",
      "year_month                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "new_df[['high', 'low', 'opening_price', 'closing_price']] = \\\n",
    "        new_df.groupby(['year', 'trading_code'])[['high', 'low', 'opening_price', 'closing_price']].transform(lambda x: x.replace(0, x.mean()))\n",
    "\n",
    "# Verify the changes\n",
    "# print the zero count of each column\n",
    "zero_counts = new_df.apply(lambda x: (x==0).sum())\n",
    "print(zero_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = new_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year\n",
       "2017    7440\n",
       "2010    7320\n",
       "2015    7320\n",
       "2022    7320\n",
       "2018    7260\n",
       "2016    7230\n",
       "2021    7200\n",
       "2013    7140\n",
       "2014    7140\n",
       "2012    7110\n",
       "2019    7110\n",
       "2011    6870\n",
       "2020    6240\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trading_code\n",
       "ALARABANK     3090\n",
       "BANKASIA      3090\n",
       "SQURPHARMA    3090\n",
       "SHAHJABANK    3090\n",
       "RENATA        3090\n",
       "RECKITTBEN    3090\n",
       "PUBALIBANK    3090\n",
       "PRIMEBANK     3090\n",
       "POWERGRID     3090\n",
       "PADMAOIL      3090\n",
       "OLYMPIC       3090\n",
       "NBL           3090\n",
       "MPETROLEUM    3090\n",
       "MARICO        3090\n",
       "LINDEBD       3090\n",
       "JAMUNAOIL     3090\n",
       "ISLAMIBANK    3090\n",
       "IFIC          3090\n",
       "GP            3090\n",
       "EBL           3090\n",
       "DUTCHBANGL    3090\n",
       "CITYBANK      3090\n",
       "BXPHARMA      3090\n",
       "BSRMSTEEL     3090\n",
       "BSC           3090\n",
       "BRACBANK      3090\n",
       "BEXIMCO       3090\n",
       "BERGERPBL     3090\n",
       "BATBC         3090\n",
       "SUMITPOWER    3090\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['trading_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208\n",
      "208\n",
      "208\n",
      "208\n",
      "208\n",
      "208\n",
      "208\n",
      "208\n",
      "208\n",
      "208\n",
      "208\n",
      "208\n",
      "208\n"
     ]
    }
   ],
   "source": [
    "# df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Create an empty DataFrame to store the sampled data\n",
    "sampled_data = pd.DataFrame()\n",
    "\n",
    "# Group the data by year\n",
    "grouped_data = df.groupby('year')\n",
    "\n",
    "# Sample 200 days for each year\n",
    "for year, group in grouped_data:\n",
    "    # Sample 200 unique days\n",
    "    for t, g in group.groupby('trading_code'):\n",
    "        sampled_days = g['date'].sample(208, replace=False)\n",
    "        break\n",
    "    # check the number of unique days\n",
    "    print(len(sampled_days.unique()))\n",
    "    \n",
    "    # Filter the data for the sampled days\n",
    "    sampled_year_data = group[group['date'].isin(sampled_days)]\n",
    "    # print(len(sampled_year_data))\n",
    "    \n",
    "    # Ensure each sampled day includes all 30 trading codes\n",
    "    sampled_year_data = sampled_year_data.groupby('date').filter(lambda x: len(x) == 30)\n",
    "    \n",
    "    # Append the sampled data to the final DataFrame\n",
    "    sampled_data = pd.concat([sampled_data, sampled_year_data])\n",
    "\n",
    "# Reset index of the final sampled data\n",
    "sampled_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year\n",
       "2010    6240\n",
       "2011    6240\n",
       "2012    6240\n",
       "2013    6240\n",
       "2014    6240\n",
       "2015    6240\n",
       "2016    6240\n",
       "2017    6240\n",
       "2018    6240\n",
       "2019    6240\n",
       "2020    6240\n",
       "2021    6240\n",
       "2022    6240\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_data['year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# change the zero values of the columns volume to hundred\n",
    "df['volume'] = df['volume'].replace(0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date                           0\n",
      "trading_code                   0\n",
      "last_traded_price           1469\n",
      "high                           0\n",
      "low                            0\n",
      "opening_price                  0\n",
      "closing_price                  0\n",
      "yesterdays_closing_price       0\n",
      "trade                       1472\n",
      "value_mn                    1493\n",
      "volume                         0\n",
      "year                           0\n",
      "month                          0\n",
      "year_month                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# print the zero count of each column\n",
    "zero_counts = df.apply(lambda x: (x==0).sum())\n",
    "print(zero_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruhul/RL/Stock-Trader/.conda/lib/python3.10/site-packages/pyfolio/pos.py:26: UserWarning: Module \"zipline.assets\" not found; mutltipliers will not be applied to position notionals.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from stable_baselines3.common.logger import configure\n",
    "from finrl.meta.data_processor import DataProcessor\n",
    "\n",
    "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "from pprint import pprint\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../FinRL\")\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finrl import config\n",
    "from finrl import config_tickers\n",
    "import os\n",
    "from finrl.main import check_and_make_directories\n",
    "from finrl.config import (\n",
    "    DATA_SAVE_DIR,\n",
    "    TRAINED_MODEL_DIR,\n",
    "    TENSORBOARD_LOG_DIR,\n",
    "    RESULTS_DIR,\n",
    "    INDICATORS,\n",
    "    TRAIN_START_DATE,\n",
    "    TRAIN_END_DATE,\n",
    "    TEST_START_DATE,\n",
    "    TEST_END_DATE,\n",
    "    TRADE_START_DATE,\n",
    "    TRADE_END_DATE,\n",
    ")\n",
    "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>trading_code</th>\n",
       "      <th>last_traded_price</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>opening_price</th>\n",
       "      <th>closing_price</th>\n",
       "      <th>yesterdays_closing_price</th>\n",
       "      <th>trade</th>\n",
       "      <th>value_mn</th>\n",
       "      <th>volume</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>year_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4719</th>\n",
       "      <td>2010-12-30</td>\n",
       "      <td>ALARABANK</td>\n",
       "      <td>67.2</td>\n",
       "      <td>67.7</td>\n",
       "      <td>65.9</td>\n",
       "      <td>65.9</td>\n",
       "      <td>66.8</td>\n",
       "      <td>65.2</td>\n",
       "      <td>3587</td>\n",
       "      <td>230.4117</td>\n",
       "      <td>3450500</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>2010-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4720</th>\n",
       "      <td>2010-12-29</td>\n",
       "      <td>ALARABANK</td>\n",
       "      <td>65.7</td>\n",
       "      <td>65.7</td>\n",
       "      <td>63.7</td>\n",
       "      <td>63.8</td>\n",
       "      <td>65.2</td>\n",
       "      <td>63.4</td>\n",
       "      <td>3925</td>\n",
       "      <td>224.6406</td>\n",
       "      <td>3457250</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>2010-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4721</th>\n",
       "      <td>2010-12-28</td>\n",
       "      <td>ALARABANK</td>\n",
       "      <td>63.6</td>\n",
       "      <td>63.9</td>\n",
       "      <td>61.5</td>\n",
       "      <td>61.8</td>\n",
       "      <td>63.4</td>\n",
       "      <td>61.8</td>\n",
       "      <td>2132</td>\n",
       "      <td>108.1101</td>\n",
       "      <td>1709500</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>2010-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4722</th>\n",
       "      <td>2010-12-27</td>\n",
       "      <td>ALARABANK</td>\n",
       "      <td>62.1</td>\n",
       "      <td>62.9</td>\n",
       "      <td>61.5</td>\n",
       "      <td>62.0</td>\n",
       "      <td>61.8</td>\n",
       "      <td>61.2</td>\n",
       "      <td>2686</td>\n",
       "      <td>142.8922</td>\n",
       "      <td>2297000</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>2010-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4723</th>\n",
       "      <td>2010-12-26</td>\n",
       "      <td>ALARABANK</td>\n",
       "      <td>61.2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>59.0</td>\n",
       "      <td>60.2</td>\n",
       "      <td>61.2</td>\n",
       "      <td>60.3</td>\n",
       "      <td>1946</td>\n",
       "      <td>96.0948</td>\n",
       "      <td>1581500</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>2010-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date trading_code  last_traded_price  high   low  opening_price  \\\n",
       "4719 2010-12-30    ALARABANK               67.2  67.7  65.9           65.9   \n",
       "4720 2010-12-29    ALARABANK               65.7  65.7  63.7           63.8   \n",
       "4721 2010-12-28    ALARABANK               63.6  63.9  61.5           61.8   \n",
       "4722 2010-12-27    ALARABANK               62.1  62.9  61.5           62.0   \n",
       "4723 2010-12-26    ALARABANK               61.2  61.5  59.0           60.2   \n",
       "\n",
       "      closing_price  yesterdays_closing_price  trade  value_mn   volume  year  \\\n",
       "4719           66.8                      65.2   3587  230.4117  3450500  2010   \n",
       "4720           65.2                      63.4   3925  224.6406  3457250  2010   \n",
       "4721           63.4                      61.8   2132  108.1101  1709500  2010   \n",
       "4722           61.8                      61.2   2686  142.8922  2297000  2010   \n",
       "4723           61.2                      60.3   1946   96.0948  1581500  2010   \n",
       "\n",
       "      month year_month  \n",
       "4719     12    2010-12  \n",
       "4720     12    2010-12  \n",
       "4721     12    2010-12  \n",
       "4722     12    2010-12  \n",
       "4723     12    2010-12  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4719</th>\n",
       "      <td>2010-12-30</td>\n",
       "      <td>ALARABANK</td>\n",
       "      <td>67.7</td>\n",
       "      <td>65.9</td>\n",
       "      <td>65.9</td>\n",
       "      <td>66.8</td>\n",
       "      <td>3450500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4720</th>\n",
       "      <td>2010-12-29</td>\n",
       "      <td>ALARABANK</td>\n",
       "      <td>65.7</td>\n",
       "      <td>63.7</td>\n",
       "      <td>63.8</td>\n",
       "      <td>65.2</td>\n",
       "      <td>3457250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4721</th>\n",
       "      <td>2010-12-28</td>\n",
       "      <td>ALARABANK</td>\n",
       "      <td>63.9</td>\n",
       "      <td>61.5</td>\n",
       "      <td>61.8</td>\n",
       "      <td>63.4</td>\n",
       "      <td>1709500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4722</th>\n",
       "      <td>2010-12-27</td>\n",
       "      <td>ALARABANK</td>\n",
       "      <td>62.9</td>\n",
       "      <td>61.5</td>\n",
       "      <td>62.0</td>\n",
       "      <td>61.8</td>\n",
       "      <td>2297000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4723</th>\n",
       "      <td>2010-12-26</td>\n",
       "      <td>ALARABANK</td>\n",
       "      <td>61.5</td>\n",
       "      <td>59.0</td>\n",
       "      <td>60.2</td>\n",
       "      <td>61.2</td>\n",
       "      <td>1581500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date        tic  high   low  open  close   volume\n",
       "4719 2010-12-30  ALARABANK  67.7  65.9  65.9   66.8  3450500\n",
       "4720 2010-12-29  ALARABANK  65.7  63.7  63.8   65.2  3457250\n",
       "4721 2010-12-28  ALARABANK  63.9  61.5  61.8   63.4  1709500\n",
       "4722 2010-12-27  ALARABANK  62.9  61.5  62.0   61.8  2297000\n",
       "4723 2010-12-26  ALARABANK  61.5  59.0  60.2   61.2  1581500"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['year_month', 'last_traded_price', 'trade', 'value_mn','yesterdays_closing_price','month','year'], axis=1, inplace=True)\n",
    "df.rename(columns={'trading_code': 'tic', 'opening_price': 'open', 'closing_price': 'close'}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['day'] = pd.to_datetime(df['date']).dt.dayofweek\n",
    "df['short_resistance']= df['high'].rolling(window=10,min_periods=0).max()\n",
    "df['short_support']= df['low'].rolling(window=10,min_periods=0).min()\n",
    "df['long_resistance']= df['high'].rolling(window=50,min_periods=0).max()\n",
    "df['long_support']= df['low'].rolling(window=50,min_periods=0).min()\n",
    "df = df.reset_index(drop=True)\n",
    "df = df.sort_values(by=['date','tic']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                datetime64[ns]\n",
       "tic                         object\n",
       "high                       float64\n",
       "low                        float64\n",
       "open                       float64\n",
       "close                      float64\n",
       "volume                       int64\n",
       "day                          int32\n",
       "short_resistance           float64\n",
       "short_support              float64\n",
       "long_resistance            float64\n",
       "long_support               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert datetime to string\n",
    "df['date'] = df['date'].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92700, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>short_resistance</th>\n",
       "      <th>short_support</th>\n",
       "      <th>long_resistance</th>\n",
       "      <th>long_support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-03</td>\n",
       "      <td>ALARABANK</td>\n",
       "      <td>530.00</td>\n",
       "      <td>516.0</td>\n",
       "      <td>530.0</td>\n",
       "      <td>522.25</td>\n",
       "      <td>128350</td>\n",
       "      <td>6</td>\n",
       "      <td>532.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>614.0</td>\n",
       "      <td>493.534091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-03</td>\n",
       "      <td>BANKASIA</td>\n",
       "      <td>459.75</td>\n",
       "      <td>437.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>452.00</td>\n",
       "      <td>298550</td>\n",
       "      <td>6</td>\n",
       "      <td>495.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>431.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-03</td>\n",
       "      <td>BATBC</td>\n",
       "      <td>436.00</td>\n",
       "      <td>407.6</td>\n",
       "      <td>414.9</td>\n",
       "      <td>432.10</td>\n",
       "      <td>467500</td>\n",
       "      <td>6</td>\n",
       "      <td>464.9</td>\n",
       "      <td>407.6</td>\n",
       "      <td>577.0</td>\n",
       "      <td>407.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-03</td>\n",
       "      <td>BERGERPBL</td>\n",
       "      <td>679.90</td>\n",
       "      <td>626.0</td>\n",
       "      <td>639.0</td>\n",
       "      <td>666.80</td>\n",
       "      <td>123850</td>\n",
       "      <td>6</td>\n",
       "      <td>722.0</td>\n",
       "      <td>626.0</td>\n",
       "      <td>728.0</td>\n",
       "      <td>555.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-03</td>\n",
       "      <td>BEXIMCO</td>\n",
       "      <td>321.00</td>\n",
       "      <td>310.1</td>\n",
       "      <td>310.1</td>\n",
       "      <td>319.90</td>\n",
       "      <td>2230100</td>\n",
       "      <td>6</td>\n",
       "      <td>328.7</td>\n",
       "      <td>310.1</td>\n",
       "      <td>398.4</td>\n",
       "      <td>310.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        tic    high    low   open   close   volume  day  \\\n",
       "0  2010-01-03  ALARABANK  530.00  516.0  530.0  522.25   128350    6   \n",
       "1  2010-01-03   BANKASIA  459.75  437.0  437.0  452.00   298550    6   \n",
       "2  2010-01-03      BATBC  436.00  407.6  414.9  432.10   467500    6   \n",
       "3  2010-01-03  BERGERPBL  679.90  626.0  639.0  666.80   123850    6   \n",
       "4  2010-01-03    BEXIMCO  321.00  310.1  310.1  319.90  2230100    6   \n",
       "\n",
       "   short_resistance  short_support  long_resistance  long_support  \n",
       "0             532.0          502.0            614.0    493.534091  \n",
       "1             495.0          431.0            590.0    431.000000  \n",
       "2             464.9          407.6            577.0    407.600000  \n",
       "3             722.0          626.0            728.0    555.000000  \n",
       "4             328.7          310.1            398.4    310.100000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3090\n"
     ]
    }
   ],
   "source": [
    "data = df.copy()\n",
    "df_price_pivot = data.pivot(index=\"date\", columns=\"tic\", values=\"close\")\n",
    "df_price_pivot = df_price_pivot.pct_change()\n",
    "unique_date = data.date.unique()\n",
    "# start after a year\n",
    "start = 208\n",
    "turbulence_index = [0] * start\n",
    "# turbulence_index = [0]\n",
    "count = 0\n",
    "for i in range(start, len(unique_date)):\n",
    "  current_price = df_price_pivot[df_price_pivot.index == unique_date[i]]\n",
    "  # use one year rolling window to calcualte covariance\n",
    "  hist_price = df_price_pivot[\n",
    "      (df_price_pivot.index < unique_date[i])\n",
    "      & (df_price_pivot.index >= unique_date[i - 208])\n",
    "  ]\n",
    "  # Drop tickers which has number missing values more than the \"oldest\" ticker\n",
    "  filtered_hist_price = hist_price.iloc[\n",
    "      hist_price.isna().sum().min() :\n",
    "  ].dropna(axis=1)\n",
    "\n",
    "  cov_temp = filtered_hist_price.cov()\n",
    "  current_temp = current_price[[x for x in filtered_hist_price]] - np.mean(\n",
    "      filtered_hist_price, axis=0\n",
    "  )\n",
    "  # cov_temp = hist_price.cov()\n",
    "  # current_temp=(current_price - np.mean(hist_price,axis=0))\n",
    "\n",
    "  temp = current_temp.values.dot(np.linalg.pinv(cov_temp)).dot(\n",
    "      current_temp.values.T\n",
    "  )\n",
    "  if temp > 0:\n",
    "      count += 1\n",
    "      if count > 2:\n",
    "          turbulence_temp = temp[0][0]\n",
    "      else:\n",
    "          # avoid large outlier because of the calculation just begins\n",
    "          turbulence_temp = 0\n",
    "  else:\n",
    "      turbulence_temp = 0\n",
    "  turbulence_index.append(turbulence_temp)\n",
    "print(len(turbulence_index))\n",
    "try:\n",
    "  turbulence_index = pd.DataFrame(\n",
    "      {\"date\": df_price_pivot.index, \"turbulence\": turbulence_index}\n",
    "  )\n",
    "except ValueError:\n",
    "  raise Exception(\"Turbulence information could not be added.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14167.284980163686"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turbulence_index['turbulence'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tic\n",
       "ALARABANK     3090\n",
       "BANKASIA      3090\n",
       "SQURPHARMA    3090\n",
       "SHAHJABANK    3090\n",
       "RENATA        3090\n",
       "RECKITTBEN    3090\n",
       "PUBALIBANK    3090\n",
       "PRIMEBANK     3090\n",
       "POWERGRID     3090\n",
       "PADMAOIL      3090\n",
       "OLYMPIC       3090\n",
       "NBL           3090\n",
       "MPETROLEUM    3090\n",
       "MARICO        3090\n",
       "LINDEBD       3090\n",
       "JAMUNAOIL     3090\n",
       "ISLAMIBANK    3090\n",
       "IFIC          3090\n",
       "GP            3090\n",
       "EBL           3090\n",
       "DUTCHBANGL    3090\n",
       "CITYBANK      3090\n",
       "BXPHARMA      3090\n",
       "BSRMSTEEL     3090\n",
       "BSC           3090\n",
       "BRACBANK      3090\n",
       "BEXIMCO       3090\n",
       "BERGERPBL     3090\n",
       "BATBC         3090\n",
       "SUMITPOWER    3090\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.merge(turbulence_index, on=\"date\")\n",
    "df['tic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureEngineer(\n",
    "                    use_technical_indicator=True,\n",
    "                    tech_indicator_list = INDICATORS,\n",
    "                    use_vix=False,\n",
    "                    use_turbulence=False,\n",
    "                    user_defined_feature = False)\n",
    "# turbulance is giving error\n",
    "df = df.fillna(value = 0)\n",
    "processed = fe.preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ticker = processed[\"tic\"].unique().tolist()\n",
    "list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
    "combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
    "processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "processed_full = processed_full.sort_values(['date','tic'])\n",
    "\n",
    "processed_full = processed_full.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92700, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>short_resistance</th>\n",
       "      <th>short_support</th>\n",
       "      <th>...</th>\n",
       "      <th>long_support</th>\n",
       "      <th>turbulence</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-03</td>\n",
       "      <td>ALARABANK</td>\n",
       "      <td>530.00000</td>\n",
       "      <td>516.000000</td>\n",
       "      <td>530.00</td>\n",
       "      <td>522.25</td>\n",
       "      <td>128350.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>532.00</td>\n",
       "      <td>502.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>493.534091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>522.478553</td>\n",
       "      <td>521.771447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>522.25</td>\n",
       "      <td>522.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-03</td>\n",
       "      <td>BANKASIA</td>\n",
       "      <td>459.75000</td>\n",
       "      <td>437.000000</td>\n",
       "      <td>437.00</td>\n",
       "      <td>452.00</td>\n",
       "      <td>298550.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>495.00</td>\n",
       "      <td>431.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>431.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>522.478553</td>\n",
       "      <td>521.771447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>452.00</td>\n",
       "      <td>452.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-03</td>\n",
       "      <td>BATBC</td>\n",
       "      <td>436.00000</td>\n",
       "      <td>407.600000</td>\n",
       "      <td>414.90</td>\n",
       "      <td>432.10</td>\n",
       "      <td>467500.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>464.90</td>\n",
       "      <td>407.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>407.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>522.478553</td>\n",
       "      <td>521.771447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>432.10</td>\n",
       "      <td>432.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-03</td>\n",
       "      <td>BERGERPBL</td>\n",
       "      <td>679.90000</td>\n",
       "      <td>626.000000</td>\n",
       "      <td>639.00</td>\n",
       "      <td>666.80</td>\n",
       "      <td>123850.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>722.00</td>\n",
       "      <td>626.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>555.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>522.478553</td>\n",
       "      <td>521.771447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>666.80</td>\n",
       "      <td>666.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-03</td>\n",
       "      <td>BEXIMCO</td>\n",
       "      <td>321.00000</td>\n",
       "      <td>310.100000</td>\n",
       "      <td>310.10</td>\n",
       "      <td>319.90</td>\n",
       "      <td>2230100.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>328.70</td>\n",
       "      <td>310.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>310.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>522.478553</td>\n",
       "      <td>521.771447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>319.90</td>\n",
       "      <td>319.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2010-01-03</td>\n",
       "      <td>BRACBANK</td>\n",
       "      <td>705.00000</td>\n",
       "      <td>680.250000</td>\n",
       "      <td>705.00</td>\n",
       "      <td>687.25</td>\n",
       "      <td>199600.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>773.00</td>\n",
       "      <td>680.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>542.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>522.478553</td>\n",
       "      <td>521.771447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>687.25</td>\n",
       "      <td>687.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2010-01-03</td>\n",
       "      <td>BSC</td>\n",
       "      <td>1814.22619</td>\n",
       "      <td>1740.761905</td>\n",
       "      <td>5490.00</td>\n",
       "      <td>5490.00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5221.00</td>\n",
       "      <td>1740.761905</td>\n",
       "      <td>...</td>\n",
       "      <td>172.727273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>522.478553</td>\n",
       "      <td>521.771447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5490.00</td>\n",
       "      <td>5490.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2010-01-03</td>\n",
       "      <td>BSRMSTEEL</td>\n",
       "      <td>1047.75000</td>\n",
       "      <td>1026.500000</td>\n",
       "      <td>1047.75</td>\n",
       "      <td>1036.50</td>\n",
       "      <td>61250.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1246.00</td>\n",
       "      <td>1026.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1026.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>522.478553</td>\n",
       "      <td>521.771447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1036.50</td>\n",
       "      <td>1036.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2010-01-03</td>\n",
       "      <td>BXPHARMA</td>\n",
       "      <td>161.30000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>156.00</td>\n",
       "      <td>160.20</td>\n",
       "      <td>582850.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>167.00</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>522.478553</td>\n",
       "      <td>521.771447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>160.20</td>\n",
       "      <td>160.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2010-01-03</td>\n",
       "      <td>CITYBANK</td>\n",
       "      <td>744.75000</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>744.75</td>\n",
       "      <td>714.50</td>\n",
       "      <td>151820.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>744.75</td>\n",
       "      <td>676.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>676.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>522.478553</td>\n",
       "      <td>521.771447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>714.50</td>\n",
       "      <td>714.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        tic        high          low     open    close  \\\n",
       "0  2010-01-03  ALARABANK   530.00000   516.000000   530.00   522.25   \n",
       "1  2010-01-03   BANKASIA   459.75000   437.000000   437.00   452.00   \n",
       "2  2010-01-03      BATBC   436.00000   407.600000   414.90   432.10   \n",
       "3  2010-01-03  BERGERPBL   679.90000   626.000000   639.00   666.80   \n",
       "4  2010-01-03    BEXIMCO   321.00000   310.100000   310.10   319.90   \n",
       "5  2010-01-03   BRACBANK   705.00000   680.250000   705.00   687.25   \n",
       "6  2010-01-03        BSC  1814.22619  1740.761905  5490.00  5490.00   \n",
       "7  2010-01-03  BSRMSTEEL  1047.75000  1026.500000  1047.75  1036.50   \n",
       "8  2010-01-03   BXPHARMA   161.30000   156.000000   156.00   160.20   \n",
       "9  2010-01-03   CITYBANK   744.75000   712.000000   744.75   714.50   \n",
       "\n",
       "      volume  day  short_resistance  short_support  ...  long_support  \\\n",
       "0   128350.0  6.0            532.00     502.000000  ...    493.534091   \n",
       "1   298550.0  6.0            495.00     431.000000  ...    431.000000   \n",
       "2   467500.0  6.0            464.90     407.600000  ...    407.600000   \n",
       "3   123850.0  6.0            722.00     626.000000  ...    555.000000   \n",
       "4  2230100.0  6.0            328.70     310.100000  ...    310.100000   \n",
       "5   199600.0  6.0            773.00     680.250000  ...    542.000000   \n",
       "6      100.0  6.0           5221.00    1740.761905  ...    172.727273   \n",
       "7    61250.0  6.0           1246.00    1026.500000  ...   1026.500000   \n",
       "8   582850.0  6.0            167.00     156.000000  ...    156.000000   \n",
       "9   151820.0  6.0            744.75     676.000000  ...    676.000000   \n",
       "\n",
       "   turbulence  macd     boll_ub     boll_lb  rsi_30     cci_30  dx_30  \\\n",
       "0         0.0   0.0  522.478553  521.771447     0.0 -66.666667  100.0   \n",
       "1         0.0   0.0  522.478553  521.771447     0.0 -66.666667  100.0   \n",
       "2         0.0   0.0  522.478553  521.771447     0.0 -66.666667  100.0   \n",
       "3         0.0   0.0  522.478553  521.771447     0.0 -66.666667  100.0   \n",
       "4         0.0   0.0  522.478553  521.771447     0.0 -66.666667  100.0   \n",
       "5         0.0   0.0  522.478553  521.771447     0.0 -66.666667  100.0   \n",
       "6         0.0   0.0  522.478553  521.771447     0.0 -66.666667  100.0   \n",
       "7         0.0   0.0  522.478553  521.771447     0.0 -66.666667  100.0   \n",
       "8         0.0   0.0  522.478553  521.771447     0.0 -66.666667  100.0   \n",
       "9         0.0   0.0  522.478553  521.771447     0.0 -66.666667  100.0   \n",
       "\n",
       "   close_30_sma  close_60_sma  \n",
       "0        522.25        522.25  \n",
       "1        452.00        452.00  \n",
       "2        432.10        432.10  \n",
       "3        666.80        666.80  \n",
       "4        319.90        319.90  \n",
       "5        687.25        687.25  \n",
       "6       5490.00       5490.00  \n",
       "7       1036.50       1036.50  \n",
       "8        160.20        160.20  \n",
       "9        714.50        714.50  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(processed_full.shape)\n",
    "processed_full.sort_values(['date','tic'],ignore_index=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvo_df = processed_full.sort_values(['date','tic'],ignore_index=True)[['date','tic','close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78180\n",
      "14520\n"
     ]
    }
   ],
   "source": [
    "TRAIN_START_DATE = '2010-01-01'\n",
    "TRAIN_END_DATE = '2020-12-31'\n",
    "TRADE_START_DATE = '2021-01-01'\n",
    "TRADE_END_DATE = '2022-12-31'\n",
    "train = data_split(processed_full, TRAIN_START_DATE,TRAIN_END_DATE)\n",
    "trade = data_split(processed_full, TRADE_START_DATE,TRADE_END_DATE)\n",
    "print(len(train))\n",
    "print(len(trade))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 30, State Space: 301\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StockTradingEnv - Init\n"
     ]
    }
   ],
   "source": [
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 1000000,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list,\n",
    "    \"sell_cost_pct\": sell_cost_list,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"cash_penalty_percentage\": 0.1\n",
    "}\n",
    "\n",
    "\n",
    "e_train_gym = StockTradingEnv(df = train, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "\n",
    "if_using_a2c = True\n",
    "if_using_ddpg = True\n",
    "if_using_ppo = True\n",
    "if_using_td3 = True\n",
    "if_using_sac = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to results/a2c\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_a2c = agent.get_model(\"a2c\")\n",
    "\n",
    "if if_using_a2c:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/a2c'\n",
    "  new_logger_a2c = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_a2c.set_logger(new_logger_a2c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 81         |\n",
      "|    iterations         | 100        |\n",
      "|    time_elapsed       | 6          |\n",
      "|    total_timesteps    | 500        |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 99         |\n",
      "|    policy_loss        | -293       |\n",
      "|    reward             | -1.2851281 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 53.2       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 89        |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | -231      |\n",
      "|    reward             | -2.073751 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 37.2      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 300        |\n",
      "|    time_elapsed       | 16         |\n",
      "|    total_timesteps    | 1500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 299        |\n",
      "|    policy_loss        | -212       |\n",
      "|    reward             | -1.8224599 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 32.9       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 93         |\n",
      "|    iterations         | 400        |\n",
      "|    time_elapsed       | 21         |\n",
      "|    total_timesteps    | 2000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.9      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 399        |\n",
      "|    policy_loss        | -208       |\n",
      "|    reward             | -2.0452542 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 31.6       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 96         |\n",
      "|    iterations         | 500        |\n",
      "|    time_elapsed       | 25         |\n",
      "|    total_timesteps    | 2500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.9      |\n",
      "|    explained_variance | 0.000425   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 499        |\n",
      "|    policy_loss        | -236       |\n",
      "|    reward             | -2.0923715 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 32.6       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 98         |\n",
      "|    iterations         | 600        |\n",
      "|    time_elapsed       | 30         |\n",
      "|    total_timesteps    | 3000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.9      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 599        |\n",
      "|    policy_loss        | -198       |\n",
      "|    reward             | -3.0382295 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 30.1       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 98         |\n",
      "|    iterations         | 700        |\n",
      "|    time_elapsed       | 35         |\n",
      "|    total_timesteps    | 3500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 699        |\n",
      "|    policy_loss        | -212       |\n",
      "|    reward             | -1.9244876 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 26.8       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 97         |\n",
      "|    iterations         | 800        |\n",
      "|    time_elapsed       | 40         |\n",
      "|    total_timesteps    | 4000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 799        |\n",
      "|    policy_loss        | -199       |\n",
      "|    reward             | -1.9662794 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 27.1       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 97         |\n",
      "|    iterations         | 900        |\n",
      "|    time_elapsed       | 46         |\n",
      "|    total_timesteps    | 4500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 899        |\n",
      "|    policy_loss        | -192       |\n",
      "|    reward             | -1.9611688 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 24.9       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 97         |\n",
      "|    iterations         | 1000       |\n",
      "|    time_elapsed       | 51         |\n",
      "|    total_timesteps    | 5000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43        |\n",
      "|    explained_variance | -2.38e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 999        |\n",
      "|    policy_loss        | -184       |\n",
      "|    reward             | -1.9999737 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 23.2       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 97        |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 56        |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | -73.7     |\n",
      "|    reward             | 2.3933012 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 10        |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 98         |\n",
      "|    iterations         | 1200       |\n",
      "|    time_elapsed       | 61         |\n",
      "|    total_timesteps    | 6000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1199       |\n",
      "|    policy_loss        | -178       |\n",
      "|    reward             | -2.0779824 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 24.1       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 97         |\n",
      "|    iterations         | 1300       |\n",
      "|    time_elapsed       | 66         |\n",
      "|    total_timesteps    | 6500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.2      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1299       |\n",
      "|    policy_loss        | -156       |\n",
      "|    reward             | -2.0177882 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 17.6       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 99         |\n",
      "|    iterations         | 1400       |\n",
      "|    time_elapsed       | 70         |\n",
      "|    total_timesteps    | 7000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.3      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1399       |\n",
      "|    policy_loss        | -170       |\n",
      "|    reward             | -1.9831003 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 17.4       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 100        |\n",
      "|    iterations         | 1500       |\n",
      "|    time_elapsed       | 74         |\n",
      "|    total_timesteps    | 7500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.3      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1499       |\n",
      "|    policy_loss        | -147       |\n",
      "|    reward             | -1.9833395 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 16.3       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 101        |\n",
      "|    iterations         | 1600       |\n",
      "|    time_elapsed       | 79         |\n",
      "|    total_timesteps    | 8000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1599       |\n",
      "|    policy_loss        | -116       |\n",
      "|    reward             | -1.5758528 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 14         |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 101        |\n",
      "|    iterations         | 1700       |\n",
      "|    time_elapsed       | 83         |\n",
      "|    total_timesteps    | 8500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1699       |\n",
      "|    policy_loss        | -145       |\n",
      "|    reward             | -1.9881718 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 13.9       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 101        |\n",
      "|    iterations         | 1800       |\n",
      "|    time_elapsed       | 88         |\n",
      "|    total_timesteps    | 9000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.4      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1799       |\n",
      "|    policy_loss        | -144       |\n",
      "|    reward             | -2.0134866 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 13.2       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 101        |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 93         |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1899       |\n",
      "|    policy_loss        | -129       |\n",
      "|    reward             | -1.8750176 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 11.3       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 102       |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 97        |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | -113      |\n",
      "|    reward             | -2.058098 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 9.75      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 103       |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 101       |\n",
      "|    total_timesteps    | 10500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2099      |\n",
      "|    policy_loss        | -250      |\n",
      "|    reward             | -1.275455 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 69.3      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 102         |\n",
      "|    iterations         | 2200        |\n",
      "|    time_elapsed       | 106         |\n",
      "|    total_timesteps    | 11000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.6       |\n",
      "|    explained_variance | 0.000806    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2199        |\n",
      "|    policy_loss        | -230        |\n",
      "|    reward             | 0.018938143 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 32.3        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 102        |\n",
      "|    iterations         | 2300       |\n",
      "|    time_elapsed       | 111        |\n",
      "|    total_timesteps    | 11500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2299       |\n",
      "|    policy_loss        | -139       |\n",
      "|    reward             | -2.1563811 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 10.8       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 102        |\n",
      "|    iterations         | 2400       |\n",
      "|    time_elapsed       | 117        |\n",
      "|    total_timesteps    | 12000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2399       |\n",
      "|    policy_loss        | -121       |\n",
      "|    reward             | -2.0202646 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 8.94       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 101        |\n",
      "|    iterations         | 2500       |\n",
      "|    time_elapsed       | 123        |\n",
      "|    total_timesteps    | 12500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2499       |\n",
      "|    policy_loss        | -89.7      |\n",
      "|    reward             | -2.5067983 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 4.61       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 101       |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 128       |\n",
      "|    total_timesteps    | 13000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | -90.5     |\n",
      "|    reward             | -2.051635 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 4.95      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 100        |\n",
      "|    iterations         | 2700       |\n",
      "|    time_elapsed       | 134        |\n",
      "|    total_timesteps    | 13500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.9      |\n",
      "|    explained_variance | 0.00451    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2699       |\n",
      "|    policy_loss        | -77.5      |\n",
      "|    reward             | -1.3490013 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 3.32       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 100       |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 139       |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | -81.8     |\n",
      "|    reward             | -2.140836 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 3.85      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 99        |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 145       |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | -89.9     |\n",
      "|    reward             | -2.18978  |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 5.13      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 99         |\n",
      "|    iterations         | 3000       |\n",
      "|    time_elapsed       | 151        |\n",
      "|    total_timesteps    | 15000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -44        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2999       |\n",
      "|    policy_loss        | -82.3      |\n",
      "|    reward             | -1.9181381 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 4.13       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 99         |\n",
      "|    iterations         | 3100       |\n",
      "|    time_elapsed       | 155        |\n",
      "|    total_timesteps    | 15500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -44.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3099       |\n",
      "|    policy_loss        | -69.4      |\n",
      "|    reward             | -1.9267391 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 3.08       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 99         |\n",
      "|    iterations         | 3200       |\n",
      "|    time_elapsed       | 160        |\n",
      "|    total_timesteps    | 16000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -44.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3199       |\n",
      "|    policy_loss        | -87.7      |\n",
      "|    reward             | -1.9332335 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 4.3        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 98         |\n",
      "|    iterations         | 3300       |\n",
      "|    time_elapsed       | 167        |\n",
      "|    total_timesteps    | 16500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -44.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3299       |\n",
      "|    policy_loss        | -40.1      |\n",
      "|    reward             | -1.6144065 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 1.24       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 98         |\n",
      "|    iterations         | 3400       |\n",
      "|    time_elapsed       | 172        |\n",
      "|    total_timesteps    | 17000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -44.1      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3399       |\n",
      "|    policy_loss        | -62.6      |\n",
      "|    reward             | -2.0410385 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 2.09       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 98         |\n",
      "|    iterations         | 3500       |\n",
      "|    time_elapsed       | 177        |\n",
      "|    total_timesteps    | 17500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -44.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3499       |\n",
      "|    policy_loss        | -47.8      |\n",
      "|    reward             | -1.8518714 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 1.37       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 98         |\n",
      "|    iterations         | 3600       |\n",
      "|    time_elapsed       | 181        |\n",
      "|    total_timesteps    | 18000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -44.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3599       |\n",
      "|    policy_loss        | -41.2      |\n",
      "|    reward             | -1.9221594 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 1.33       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 99         |\n",
      "|    iterations         | 3700       |\n",
      "|    time_elapsed       | 186        |\n",
      "|    total_timesteps    | 18500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -44.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3699       |\n",
      "|    policy_loss        | -66.2      |\n",
      "|    reward             | -4.9155107 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 9.73       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 99        |\n",
      "|    iterations         | 3800      |\n",
      "|    time_elapsed       | 190       |\n",
      "|    total_timesteps    | 19000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3799      |\n",
      "|    policy_loss        | -22.4     |\n",
      "|    reward             | -2.538339 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 0.49      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 99        |\n",
      "|    iterations         | 3900      |\n",
      "|    time_elapsed       | 195       |\n",
      "|    total_timesteps    | 19500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.5     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3899      |\n",
      "|    policy_loss        | -53.8     |\n",
      "|    reward             | -2.243446 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 1.63      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 99        |\n",
      "|    iterations         | 4000      |\n",
      "|    time_elapsed       | 200       |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | -24.5     |\n",
      "|    reward             | -2.030554 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 0.466     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 99         |\n",
      "|    iterations         | 4100       |\n",
      "|    time_elapsed       | 206        |\n",
      "|    total_timesteps    | 20500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -44.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4099       |\n",
      "|    policy_loss        | -20.9      |\n",
      "|    reward             | -2.1061358 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 0.322      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 99         |\n",
      "|    iterations         | 4200       |\n",
      "|    time_elapsed       | 211        |\n",
      "|    total_timesteps    | 21000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -44.8      |\n",
      "|    explained_variance | -2.38e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4199       |\n",
      "|    policy_loss        | 71.9       |\n",
      "|    reward             | -1.1374705 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 3.52       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 99         |\n",
      "|    iterations         | 4300       |\n",
      "|    time_elapsed       | 216        |\n",
      "|    total_timesteps    | 21500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -44.8      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4299       |\n",
      "|    policy_loss        | -8.47      |\n",
      "|    reward             | -1.9429556 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 0.0946     |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 98       |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 222      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -46.5    |\n",
      "|    reward             | -2.67173 |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 1.37     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 98        |\n",
      "|    iterations         | 4500      |\n",
      "|    time_elapsed       | 227       |\n",
      "|    total_timesteps    | 22500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4499      |\n",
      "|    policy_loss        | -6.47     |\n",
      "|    reward             | -1.703225 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 0.0349    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 98         |\n",
      "|    iterations         | 4600       |\n",
      "|    time_elapsed       | 232        |\n",
      "|    total_timesteps    | 23000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -45.1      |\n",
      "|    explained_variance | 0.000207   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4599       |\n",
      "|    policy_loss        | -1.91      |\n",
      "|    reward             | -1.7974046 |\n",
      "|    std                | 1.09       |\n",
      "|    value_loss         | 0.0302     |\n",
      "--------------------------------------\n",
      "day: 2605, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 544297.27\n",
      "total_reward: -455702.73\n",
      "total_cost: 10139.38\n",
      "total_trades: 46761\n",
      "Sharpe: -0.014\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 98        |\n",
      "|    iterations         | 4700      |\n",
      "|    time_elapsed       | 238       |\n",
      "|    total_timesteps    | 23500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4699      |\n",
      "|    policy_loss        | -85.7     |\n",
      "|    reward             | -4.158388 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 5.08      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 98         |\n",
      "|    iterations         | 4800       |\n",
      "|    time_elapsed       | 244        |\n",
      "|    total_timesteps    | 24000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -45.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4799       |\n",
      "|    policy_loss        | 12.3       |\n",
      "|    reward             | -1.8843315 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 0.121      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 97        |\n",
      "|    iterations         | 4900      |\n",
      "|    time_elapsed       | 250       |\n",
      "|    total_timesteps    | 24500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.6     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4899      |\n",
      "|    policy_loss        | -0.763    |\n",
      "|    reward             | -1.969705 |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 0.0442    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 97         |\n",
      "|    iterations         | 5000       |\n",
      "|    time_elapsed       | 256        |\n",
      "|    total_timesteps    | 25000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -45.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4999       |\n",
      "|    policy_loss        | -5.1       |\n",
      "|    reward             | -2.0921862 |\n",
      "|    std                | 1.12       |\n",
      "|    value_loss         | 0.0147     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 97         |\n",
      "|    iterations         | 5100       |\n",
      "|    time_elapsed       | 261        |\n",
      "|    total_timesteps    | 25500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -46.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5099       |\n",
      "|    policy_loss        | -11.1      |\n",
      "|    reward             | -2.0519795 |\n",
      "|    std                | 1.13       |\n",
      "|    value_loss         | 0.0841     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 96        |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 268       |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.6     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | -3.33     |\n",
      "|    reward             | -2.018371 |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 0.00842   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 96         |\n",
      "|    iterations         | 5300       |\n",
      "|    time_elapsed       | 273        |\n",
      "|    total_timesteps    | 26500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -46.6      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5299       |\n",
      "|    policy_loss        | -11.2      |\n",
      "|    reward             | -2.0713744 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 0.518      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 96        |\n",
      "|    iterations         | 5400      |\n",
      "|    time_elapsed       | 278       |\n",
      "|    total_timesteps    | 27000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.8     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5399      |\n",
      "|    policy_loss        | -12.9     |\n",
      "|    reward             | -2.114808 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 0.418     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 96         |\n",
      "|    iterations         | 5500       |\n",
      "|    time_elapsed       | 283        |\n",
      "|    total_timesteps    | 27500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -46.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5499       |\n",
      "|    policy_loss        | 14         |\n",
      "|    reward             | -2.1611419 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 0.125      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 96         |\n",
      "|    iterations         | 5600       |\n",
      "|    time_elapsed       | 289        |\n",
      "|    total_timesteps    | 28000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -47.3      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5599       |\n",
      "|    policy_loss        | -0.72      |\n",
      "|    reward             | -2.1051965 |\n",
      "|    std                | 1.17       |\n",
      "|    value_loss         | 0.00915    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 96         |\n",
      "|    iterations         | 5700       |\n",
      "|    time_elapsed       | 294        |\n",
      "|    total_timesteps    | 28500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -47.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5699       |\n",
      "|    policy_loss        | -13.4      |\n",
      "|    reward             | -2.4413176 |\n",
      "|    std                | 1.18       |\n",
      "|    value_loss         | 0.18       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 96         |\n",
      "|    iterations         | 5800       |\n",
      "|    time_elapsed       | 301        |\n",
      "|    total_timesteps    | 29000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -47.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5799       |\n",
      "|    policy_loss        | -99.5      |\n",
      "|    reward             | -2.0991066 |\n",
      "|    std                | 1.18       |\n",
      "|    value_loss         | 11.4       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 96         |\n",
      "|    iterations         | 5900       |\n",
      "|    time_elapsed       | 306        |\n",
      "|    total_timesteps    | 29500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -47.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5899       |\n",
      "|    policy_loss        | -7.19      |\n",
      "|    reward             | -2.1001723 |\n",
      "|    std                | 1.19       |\n",
      "|    value_loss         | 0.0411     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 96        |\n",
      "|    iterations         | 6000      |\n",
      "|    time_elapsed       | 312       |\n",
      "|    total_timesteps    | 30000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.9     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5999      |\n",
      "|    policy_loss        | 0.127     |\n",
      "|    reward             | -2.055941 |\n",
      "|    std                | 1.2       |\n",
      "|    value_loss         | 0.00859   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 95         |\n",
      "|    iterations         | 6100       |\n",
      "|    time_elapsed       | 318        |\n",
      "|    total_timesteps    | 30500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -48.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6099       |\n",
      "|    policy_loss        | -0.882     |\n",
      "|    reward             | -1.9813241 |\n",
      "|    std                | 1.21       |\n",
      "|    value_loss         | 0.00209    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 95        |\n",
      "|    iterations         | 6200      |\n",
      "|    time_elapsed       | 324       |\n",
      "|    total_timesteps    | 31000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -48.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6199      |\n",
      "|    policy_loss        | -2.91     |\n",
      "|    reward             | -2.015595 |\n",
      "|    std                | 1.23      |\n",
      "|    value_loss         | 0.00426   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 94        |\n",
      "|    iterations         | 6300      |\n",
      "|    time_elapsed       | 333       |\n",
      "|    total_timesteps    | 31500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -49.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6299      |\n",
      "|    policy_loss        | 6.77      |\n",
      "|    reward             | -2.840973 |\n",
      "|    std                | 1.25      |\n",
      "|    value_loss         | 1.11      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 94        |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 339       |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -49.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | 28.2      |\n",
      "|    reward             | -2.548912 |\n",
      "|    std                | 1.25      |\n",
      "|    value_loss         | 1.21      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 94         |\n",
      "|    iterations         | 6500       |\n",
      "|    time_elapsed       | 345        |\n",
      "|    total_timesteps    | 32500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -49.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6499       |\n",
      "|    policy_loss        | -38.1      |\n",
      "|    reward             | -2.1841533 |\n",
      "|    std                | 1.25       |\n",
      "|    value_loss         | 1.29       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 94         |\n",
      "|    iterations         | 6600       |\n",
      "|    time_elapsed       | 350        |\n",
      "|    total_timesteps    | 33000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -49.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6599       |\n",
      "|    policy_loss        | -16.1      |\n",
      "|    reward             | -2.8163557 |\n",
      "|    std                | 1.25       |\n",
      "|    value_loss         | 0.139      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 93         |\n",
      "|    iterations         | 6700       |\n",
      "|    time_elapsed       | 356        |\n",
      "|    total_timesteps    | 33500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -49.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6699       |\n",
      "|    policy_loss        | -11        |\n",
      "|    reward             | -2.8847125 |\n",
      "|    std                | 1.25       |\n",
      "|    value_loss         | 0.168      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 93         |\n",
      "|    iterations         | 6800       |\n",
      "|    time_elapsed       | 363        |\n",
      "|    total_timesteps    | 34000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -49.3      |\n",
      "|    explained_variance | -2.38e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6799       |\n",
      "|    policy_loss        | -195       |\n",
      "|    reward             | -2.4720333 |\n",
      "|    std                | 1.25       |\n",
      "|    value_loss         | 24.9       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 93         |\n",
      "|    iterations         | 6900       |\n",
      "|    time_elapsed       | 369        |\n",
      "|    total_timesteps    | 34500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -49.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6899       |\n",
      "|    policy_loss        | -26.7      |\n",
      "|    reward             | -1.1480843 |\n",
      "|    std                | 1.26       |\n",
      "|    value_loss         | 0.365      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 93         |\n",
      "|    iterations         | 7000       |\n",
      "|    time_elapsed       | 375        |\n",
      "|    total_timesteps    | 35000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -49.4      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6999       |\n",
      "|    policy_loss        | 6.15       |\n",
      "|    reward             | -2.1484723 |\n",
      "|    std                | 1.26       |\n",
      "|    value_loss         | 0.0212     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 92        |\n",
      "|    iterations         | 7100      |\n",
      "|    time_elapsed       | 382       |\n",
      "|    total_timesteps    | 35500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -49.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7099      |\n",
      "|    policy_loss        | 25.9      |\n",
      "|    reward             | -2.031827 |\n",
      "|    std                | 1.27      |\n",
      "|    value_loss         | 0.307     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 7200       |\n",
      "|    time_elapsed       | 388        |\n",
      "|    total_timesteps    | 36000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -50.1      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7199       |\n",
      "|    policy_loss        | 12.4       |\n",
      "|    reward             | -2.0245013 |\n",
      "|    std                | 1.29       |\n",
      "|    value_loss         | 0.0898     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 7300       |\n",
      "|    time_elapsed       | 395        |\n",
      "|    total_timesteps    | 36500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -50.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7299       |\n",
      "|    policy_loss        | 87.1       |\n",
      "|    reward             | 0.23427038 |\n",
      "|    std                | 1.3        |\n",
      "|    value_loss         | 4.69       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 7400       |\n",
      "|    time_elapsed       | 401        |\n",
      "|    total_timesteps    | 37000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -50.4      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7399       |\n",
      "|    policy_loss        | 163        |\n",
      "|    reward             | -1.6056576 |\n",
      "|    std                | 1.3        |\n",
      "|    value_loss         | 12.5       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 92        |\n",
      "|    iterations         | 7500      |\n",
      "|    time_elapsed       | 406       |\n",
      "|    total_timesteps    | 37500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -50.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7499      |\n",
      "|    policy_loss        | 8.81      |\n",
      "|    reward             | -2.221197 |\n",
      "|    std                | 1.3       |\n",
      "|    value_loss         | 0.872     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 7600       |\n",
      "|    time_elapsed       | 411        |\n",
      "|    total_timesteps    | 38000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -50.5      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7599       |\n",
      "|    policy_loss        | -18.5      |\n",
      "|    reward             | -1.8122119 |\n",
      "|    std                | 1.31       |\n",
      "|    value_loss         | 0.173      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 7700       |\n",
      "|    time_elapsed       | 416        |\n",
      "|    total_timesteps    | 38500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -50.7      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7699       |\n",
      "|    policy_loss        | -13.7      |\n",
      "|    reward             | -2.0803473 |\n",
      "|    std                | 1.31       |\n",
      "|    value_loss         | 0.0749     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 7800       |\n",
      "|    time_elapsed       | 421        |\n",
      "|    total_timesteps    | 39000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -50.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7799       |\n",
      "|    policy_loss        | 32.8       |\n",
      "|    reward             | -2.6374586 |\n",
      "|    std                | 1.32       |\n",
      "|    value_loss         | 0.646      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 7900       |\n",
      "|    time_elapsed       | 426        |\n",
      "|    total_timesteps    | 39500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -50.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7899       |\n",
      "|    policy_loss        | 8.91       |\n",
      "|    reward             | -2.2996454 |\n",
      "|    std                | 1.32       |\n",
      "|    value_loss         | 0.212      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 8000       |\n",
      "|    time_elapsed       | 431        |\n",
      "|    total_timesteps    | 40000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -51        |\n",
      "|    explained_variance | 0.000597   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7999       |\n",
      "|    policy_loss        | 55.6       |\n",
      "|    reward             | -1.9210202 |\n",
      "|    std                | 1.33       |\n",
      "|    value_loss         | 1.31       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 8100       |\n",
      "|    time_elapsed       | 438        |\n",
      "|    total_timesteps    | 40500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -51.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8099       |\n",
      "|    policy_loss        | 18.3       |\n",
      "|    reward             | -1.4752374 |\n",
      "|    std                | 1.33       |\n",
      "|    value_loss         | 0.504      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 8200       |\n",
      "|    time_elapsed       | 444        |\n",
      "|    total_timesteps    | 41000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -51.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8199       |\n",
      "|    policy_loss        | -13.8      |\n",
      "|    reward             | -2.1526544 |\n",
      "|    std                | 1.34       |\n",
      "|    value_loss         | 0.0792     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 91         |\n",
      "|    iterations         | 8300       |\n",
      "|    time_elapsed       | 451        |\n",
      "|    total_timesteps    | 41500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -51.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8299       |\n",
      "|    policy_loss        | -12.5      |\n",
      "|    reward             | -1.2509443 |\n",
      "|    std                | 1.35       |\n",
      "|    value_loss         | 0.0866     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 91         |\n",
      "|    iterations         | 8400       |\n",
      "|    time_elapsed       | 457        |\n",
      "|    total_timesteps    | 42000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -51.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8399       |\n",
      "|    policy_loss        | 80.7       |\n",
      "|    reward             | -1.4874437 |\n",
      "|    std                | 1.35       |\n",
      "|    value_loss         | 2.87       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 91         |\n",
      "|    iterations         | 8500       |\n",
      "|    time_elapsed       | 462        |\n",
      "|    total_timesteps    | 42500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -51.6      |\n",
      "|    explained_variance | 0.000401   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8499       |\n",
      "|    policy_loss        | 112        |\n",
      "|    reward             | -2.5219243 |\n",
      "|    std                | 1.35       |\n",
      "|    value_loss         | 4.97       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 91         |\n",
      "|    iterations         | 8600       |\n",
      "|    time_elapsed       | 468        |\n",
      "|    total_timesteps    | 43000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -51.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8599       |\n",
      "|    policy_loss        | 32.7       |\n",
      "|    reward             | -1.8226062 |\n",
      "|    std                | 1.35       |\n",
      "|    value_loss         | 0.757      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 91         |\n",
      "|    iterations         | 8700       |\n",
      "|    time_elapsed       | 473        |\n",
      "|    total_timesteps    | 43500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -51.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8699       |\n",
      "|    policy_loss        | 2.46       |\n",
      "|    reward             | -2.2808325 |\n",
      "|    std                | 1.35       |\n",
      "|    value_loss         | 0.0708     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 91         |\n",
      "|    iterations         | 8800       |\n",
      "|    time_elapsed       | 479        |\n",
      "|    total_timesteps    | 44000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -51.7      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8799       |\n",
      "|    policy_loss        | 14.8       |\n",
      "|    reward             | -1.5547056 |\n",
      "|    std                | 1.36       |\n",
      "|    value_loss         | 0.0992     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 91         |\n",
      "|    iterations         | 8900       |\n",
      "|    time_elapsed       | 485        |\n",
      "|    total_timesteps    | 44500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -51.7      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8899       |\n",
      "|    policy_loss        | 3.47       |\n",
      "|    reward             | -1.6360246 |\n",
      "|    std                | 1.36       |\n",
      "|    value_loss         | 0.181      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 91         |\n",
      "|    iterations         | 9000       |\n",
      "|    time_elapsed       | 490        |\n",
      "|    total_timesteps    | 45000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -51.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8999       |\n",
      "|    policy_loss        | -1.86      |\n",
      "|    reward             | -1.8432388 |\n",
      "|    std                | 1.36       |\n",
      "|    value_loss         | 0.0423     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 91         |\n",
      "|    iterations         | 9100       |\n",
      "|    time_elapsed       | 496        |\n",
      "|    total_timesteps    | 45500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -51.8      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9099       |\n",
      "|    policy_loss        | 14.3       |\n",
      "|    reward             | -2.0215294 |\n",
      "|    std                | 1.36       |\n",
      "|    value_loss         | 0.0778     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 91         |\n",
      "|    iterations         | 9200       |\n",
      "|    time_elapsed       | 502        |\n",
      "|    total_timesteps    | 46000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -51.9      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9199       |\n",
      "|    policy_loss        | -20.4      |\n",
      "|    reward             | -1.6392363 |\n",
      "|    std                | 1.37       |\n",
      "|    value_loss         | 0.396      |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 91       |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 509      |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -52      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | -22      |\n",
      "|    reward             | -2.14218 |\n",
      "|    std                | 1.37     |\n",
      "|    value_loss         | 0.236    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 91        |\n",
      "|    iterations         | 9400      |\n",
      "|    time_elapsed       | 515       |\n",
      "|    total_timesteps    | 47000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -52.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9399      |\n",
      "|    policy_loss        | -429      |\n",
      "|    reward             | 7.4557166 |\n",
      "|    std                | 1.38      |\n",
      "|    value_loss         | 65.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 91        |\n",
      "|    iterations         | 9500      |\n",
      "|    time_elapsed       | 520       |\n",
      "|    total_timesteps    | 47500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -52.1     |\n",
      "|    explained_variance | -0.000243 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9499      |\n",
      "|    policy_loss        | -33.3     |\n",
      "|    reward             | -1.623225 |\n",
      "|    std                | 1.38      |\n",
      "|    value_loss         | 0.493     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 91         |\n",
      "|    iterations         | 9600       |\n",
      "|    time_elapsed       | 526        |\n",
      "|    total_timesteps    | 48000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -52.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9599       |\n",
      "|    policy_loss        | 14.1       |\n",
      "|    reward             | -2.2325149 |\n",
      "|    std                | 1.38       |\n",
      "|    value_loss         | 0.167      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 91         |\n",
      "|    iterations         | 9700       |\n",
      "|    time_elapsed       | 531        |\n",
      "|    total_timesteps    | 48500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -52.3      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9699       |\n",
      "|    policy_loss        | 18.5       |\n",
      "|    reward             | -2.0012317 |\n",
      "|    std                | 1.39       |\n",
      "|    value_loss         | 0.334      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 91         |\n",
      "|    iterations         | 9800       |\n",
      "|    time_elapsed       | 536        |\n",
      "|    total_timesteps    | 49000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -52.4      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9799       |\n",
      "|    policy_loss        | -8.64      |\n",
      "|    reward             | -2.0574718 |\n",
      "|    std                | 1.39       |\n",
      "|    value_loss         | 0.0362     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 91         |\n",
      "|    iterations         | 9900       |\n",
      "|    time_elapsed       | 542        |\n",
      "|    total_timesteps    | 49500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -52.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9899       |\n",
      "|    policy_loss        | 44.5       |\n",
      "|    reward             | -0.9653235 |\n",
      "|    std                | 1.4        |\n",
      "|    value_loss         | 0.996      |\n",
      "--------------------------------------\n",
      "day: 2605, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 560718.75\n",
      "total_reward: -439281.25\n",
      "total_cost: 5200.52\n",
      "total_trades: 46405\n",
      "Sharpe: -0.025\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 91         |\n",
      "|    iterations         | 10000      |\n",
      "|    time_elapsed       | 547        |\n",
      "|    total_timesteps    | 50000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -52.5      |\n",
      "|    explained_variance | 1.72e-05   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9999       |\n",
      "|    policy_loss        | -48.5      |\n",
      "|    reward             | -0.3563895 |\n",
      "|    std                | 1.4        |\n",
      "|    value_loss         | 1.65       |\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                             tb_log_name='a2c',\n",
    "                             total_timesteps=50000) if if_using_a2c else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
      "Using cpu device\n",
      "Logging to results/ddpg\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_ddpg = agent.get_model(\"ddpg\")\n",
    "\n",
    "if if_using_ddpg:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/ddpg'\n",
    "  new_logger_ddpg = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_ddpg.set_logger(new_logger_ddpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_ddpg = agent.train_model(model=model_ddpg,\n",
    "                             tb_log_name='ddpg',\n",
    "                             total_timesteps=50000) if if_using_ddpg else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to results/ppo\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)\n",
    "\n",
    "if if_using_ppo:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/ppo'\n",
    "  new_logger_ppo = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_ppo.set_logger(new_logger_ppo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    fps             | 62        |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 32        |\n",
      "|    total_timesteps | 2048      |\n",
      "| train/             |           |\n",
      "|    reward          | 1.9690489 |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 66          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014264977 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.2       |\n",
      "|    explained_variance   | -0.0122     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.85        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    reward               | -0.23267356 |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 11.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013272027 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.2       |\n",
      "|    explained_variance   | 0.00327     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.8        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    reward               | 2.0128894   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 35.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018971011 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.3       |\n",
      "|    explained_variance   | 0.0066      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24.8        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    reward               | 1.8397616   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 48.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 162        |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01756508 |\n",
      "|    clip_fraction        | 0.21       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.3      |\n",
      "|    explained_variance   | -0.0379    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.35       |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0276    |\n",
      "|    reward               | -1.9081799 |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 16.1       |\n",
      "----------------------------------------\n",
      "day: 2956, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3774977.58\n",
      "total_reward: 2774977.58\n",
      "total_cost: 401887.21\n",
      "total_trades: 81671\n",
      "Sharpe: 0.753\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 195         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026475038 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.4       |\n",
      "|    explained_variance   | 0.0106      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0221     |\n",
      "|    reward               | 0.057799082 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 46.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 228         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018429227 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.5       |\n",
      "|    explained_variance   | -0.00545    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 39.2        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    reward               | 1.7880479   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 54.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 260         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021180721 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.6       |\n",
      "|    explained_variance   | -0.0165     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.84        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    reward               | -2.2737408  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 19.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 292        |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02675029 |\n",
      "|    clip_fraction        | 0.242      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.6      |\n",
      "|    explained_variance   | -0.00406   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 7.41       |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0204    |\n",
      "|    reward               | 0.98894453 |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 40.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 326         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021093076 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.7       |\n",
      "|    explained_variance   | 0.00926     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 19.7        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.022      |\n",
      "|    reward               | -1.6284031  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 39          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 355         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020121586 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.7       |\n",
      "|    explained_variance   | 0.000924    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.8        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0236     |\n",
      "|    reward               | 0.22854926  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 25.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 389         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019215219 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.8       |\n",
      "|    explained_variance   | -0.00472    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.42        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0247     |\n",
      "|    reward               | 0.4193624   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 11.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 423         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.0126833   |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.8       |\n",
      "|    explained_variance   | 0.0292      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    reward               | -0.13859338 |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 38.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 457         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023029715 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.8       |\n",
      "|    explained_variance   | 0.0295      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0227     |\n",
      "|    reward               | 3.8744738   |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 27          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 487         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024224166 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.9       |\n",
      "|    explained_variance   | 0.113       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.35        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0252     |\n",
      "|    reward               | -0.26325637 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 9.92        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 520         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018783428 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42         |\n",
      "|    explained_variance   | 0.0388      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    reward               | 0.24681076  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 37.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 552         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024655312 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42         |\n",
      "|    explained_variance   | -0.007      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00996    |\n",
      "|    reward               | -1.8455201  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 40.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 586         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019520486 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.1       |\n",
      "|    explained_variance   | -0.0287     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.11        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0251     |\n",
      "|    reward               | -3.1618273  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 9.79        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 617         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027095716 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.1       |\n",
      "|    explained_variance   | 0.0527      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.31        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.022      |\n",
      "|    reward               | -0.55852425 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 17.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 62         |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 651        |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02232542 |\n",
      "|    clip_fraction        | 0.244      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -42.2      |\n",
      "|    explained_variance   | -0.0103    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 14.8       |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.0244    |\n",
      "|    reward               | -2.0887594 |\n",
      "|    std                  | 1.04       |\n",
      "|    value_loss           | 29.7       |\n",
      "----------------------------------------\n",
      "day: 2956, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2970639.96\n",
      "total_reward: 1970639.96\n",
      "total_cost: 343994.69\n",
      "total_trades: 77702\n",
      "Sharpe: 0.613\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 685         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030464383 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.2       |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.84        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    reward               | -0.31706023 |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 9.59        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 718         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025304668 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.3       |\n",
      "|    explained_variance   | -0.0297     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.7         |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0209     |\n",
      "|    reward               | -0.2382796  |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 20.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 748         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026483834 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.3       |\n",
      "|    explained_variance   | -0.00439    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.91        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0269     |\n",
      "|    reward               | -1.159043   |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 15.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 781         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027692135 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.4       |\n",
      "|    explained_variance   | -0.00753    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.84        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    reward               | 0.2796967   |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 14.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 814         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023373984 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.4       |\n",
      "|    explained_variance   | 0.0275      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.9         |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0242     |\n",
      "|    reward               | 1.1403084   |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 8.83        |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_ppo = agent.train_model(model=model_ppo, \n",
    "                             tb_log_name='ppo',\n",
    "                             total_timesteps=50000) if if_using_ppo else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent 4: TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
      "Using cpu device\n",
      "Logging to results/td3\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "TD3_PARAMS = {\"batch_size\": 100, \n",
    "              \"buffer_size\": 1000000, \n",
    "              \"learning_rate\": 0.001}\n",
    "\n",
    "model_td3 = agent.get_model(\"td3\",model_kwargs = TD3_PARAMS)\n",
    "\n",
    "if if_using_td3:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/td3'\n",
    "  new_logger_td3 = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_td3.set_logger(new_logger_td3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 4          |\n",
      "|    fps             | 24         |\n",
      "|    time_elapsed    | 485        |\n",
      "|    total_timesteps | 11828      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -18.2      |\n",
      "|    critic_loss     | 3.05e+03   |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 8871       |\n",
      "|    reward          | -5.4769893 |\n",
      "-----------------------------------\n",
      "day: 2956, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3288091.49\n",
      "total_reward: 2288091.49\n",
      "total_cost: 1185.23\n",
      "total_trades: 59158\n",
      "Sharpe: 0.619\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 8          |\n",
      "|    fps             | 21         |\n",
      "|    time_elapsed    | 1092       |\n",
      "|    total_timesteps | 23656      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 9.12       |\n",
      "|    critic_loss     | 83.9       |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 20699      |\n",
      "|    reward          | -5.4769893 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 12         |\n",
      "|    fps             | 20         |\n",
      "|    time_elapsed    | 1711       |\n",
      "|    total_timesteps | 35484      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 12.4       |\n",
      "|    critic_loss     | 6.69       |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 32527      |\n",
      "|    reward          | -5.4769893 |\n",
      "-----------------------------------\n",
      "day: 2956, episode: 70\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3288091.49\n",
      "total_reward: 2288091.49\n",
      "total_cost: 1185.23\n",
      "total_trades: 59158\n",
      "Sharpe: 0.619\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 16         |\n",
      "|    fps             | 20         |\n",
      "|    time_elapsed    | 2337       |\n",
      "|    total_timesteps | 47312      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 15.4       |\n",
      "|    critic_loss     | 22         |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 44355      |\n",
      "|    reward          | -5.4769893 |\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_td3 = agent.train_model(model=model_td3, \n",
    "                             tb_log_name='td3',\n",
    "                             total_timesteps=50000) if if_using_td3 else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent 5: SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 100000, 'learning_rate': 0.0001, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
      "Using cpu device\n",
      "Logging to results/sac\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "SAC_PARAMS = {\n",
    "    \"batch_size\": 128,\n",
    "    \"buffer_size\": 100000,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"learning_starts\": 100,\n",
    "    \"ent_coef\": \"auto_0.1\",\n",
    "}\n",
    "\n",
    "model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)\n",
    "\n",
    "if if_using_sac:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/sac'\n",
    "  new_logger_sac = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_sac.set_logger(new_logger_sac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 4          |\n",
      "|    fps             | 19         |\n",
      "|    time_elapsed    | 599        |\n",
      "|    total_timesteps | 11828      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 267        |\n",
      "|    critic_loss     | 20.6       |\n",
      "|    ent_coef        | 0.0815     |\n",
      "|    ent_coef_loss   | -114       |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 11727      |\n",
      "|    reward          | -3.5861566 |\n",
      "-----------------------------------\n",
      "day: 2956, episode: 80\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3861827.22\n",
      "total_reward: 2861827.22\n",
      "total_cost: 18573.40\n",
      "total_trades: 51384\n",
      "Sharpe: 0.753\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 19        |\n",
      "|    time_elapsed    | 1215      |\n",
      "|    total_timesteps | 23656     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 105       |\n",
      "|    critic_loss     | 28.3      |\n",
      "|    ent_coef        | 0.0251    |\n",
      "|    ent_coef_loss   | -160      |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 23555     |\n",
      "|    reward          | -3.716044 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 19        |\n",
      "|    time_elapsed    | 1838      |\n",
      "|    total_timesteps | 35484     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 49.8      |\n",
      "|    critic_loss     | 37.6      |\n",
      "|    ent_coef        | 0.00776   |\n",
      "|    ent_coef_loss   | -193      |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 35383     |\n",
      "|    reward          | -4.683935 |\n",
      "----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 16         |\n",
      "|    fps             | 19         |\n",
      "|    time_elapsed    | 2468       |\n",
      "|    total_timesteps | 47312      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 31.3       |\n",
      "|    critic_loss     | 2.79       |\n",
      "|    ent_coef        | 0.00247    |\n",
      "|    ent_coef_loss   | -155       |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 47211      |\n",
      "|    reward          | -3.3984547 |\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_sac = agent.train_model(model=model_sac, \n",
    "                             tb_log_name='sac',\n",
    "                             total_timesteps=50000) if if_using_sac else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_risk_indicator = processed_full[(processed_full.date<TRAIN_END_DATE) & (processed_full.date>=TRAIN_START_DATE)]\n",
    "insample_risk_indicator = data_risk_indicator.drop_duplicates(subset=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     2606.000000\n",
       "mean        47.882787\n",
       "std        296.336988\n",
       "min          0.000000\n",
       "25%         14.500062\n",
       "50%         24.600754\n",
       "75%         42.544783\n",
       "max      14167.284980\n",
       "Name: turbulence, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.turbulence.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "634.368657157683"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.turbulence.quantile(0.996)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_trade_gym = StockTradingEnv(df = trade, turbulence_threshold = 100, **env_kwargs)\n",
    "# env_trade, obs_trade = e_trade_gym.get_sb_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>short_resistance</th>\n",
       "      <th>short_support</th>\n",
       "      <th>...</th>\n",
       "      <th>long_support</th>\n",
       "      <th>turbulence</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>ALARABANK</td>\n",
       "      <td>22.1</td>\n",
       "      <td>21.5</td>\n",
       "      <td>22.1</td>\n",
       "      <td>21.9</td>\n",
       "      <td>1117376.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>23.6</td>\n",
       "      <td>21.5</td>\n",
       "      <td>...</td>\n",
       "      <td>20.1</td>\n",
       "      <td>104.317247</td>\n",
       "      <td>0.274896</td>\n",
       "      <td>23.318506</td>\n",
       "      <td>21.361494</td>\n",
       "      <td>57.821012</td>\n",
       "      <td>-33.282905</td>\n",
       "      <td>13.199225</td>\n",
       "      <td>22.146667</td>\n",
       "      <td>20.186667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>BANKASIA</td>\n",
       "      <td>18.1</td>\n",
       "      <td>17.8</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>286531.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.6</td>\n",
       "      <td>17.8</td>\n",
       "      <td>...</td>\n",
       "      <td>16.2</td>\n",
       "      <td>104.317247</td>\n",
       "      <td>-0.062325</td>\n",
       "      <td>18.695997</td>\n",
       "      <td>17.844003</td>\n",
       "      <td>47.255202</td>\n",
       "      <td>-117.224880</td>\n",
       "      <td>19.980683</td>\n",
       "      <td>18.246667</td>\n",
       "      <td>18.368333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>BATBC</td>\n",
       "      <td>1254.6</td>\n",
       "      <td>1191.0</td>\n",
       "      <td>1191.0</td>\n",
       "      <td>1249.4</td>\n",
       "      <td>228763.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1413.0</td>\n",
       "      <td>1184.0</td>\n",
       "      <td>...</td>\n",
       "      <td>555.0</td>\n",
       "      <td>104.317247</td>\n",
       "      <td>29.420587</td>\n",
       "      <td>1199.363592</td>\n",
       "      <td>1002.076408</td>\n",
       "      <td>71.029616</td>\n",
       "      <td>279.947144</td>\n",
       "      <td>64.397042</td>\n",
       "      <td>1079.650000</td>\n",
       "      <td>1084.411667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>BERGERPBL</td>\n",
       "      <td>1470.0</td>\n",
       "      <td>1429.5</td>\n",
       "      <td>1429.5</td>\n",
       "      <td>1463.2</td>\n",
       "      <td>14184.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1576.9</td>\n",
       "      <td>1420.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1420.0</td>\n",
       "      <td>104.317247</td>\n",
       "      <td>20.824021</td>\n",
       "      <td>1490.759444</td>\n",
       "      <td>1347.870556</td>\n",
       "      <td>59.939370</td>\n",
       "      <td>97.314504</td>\n",
       "      <td>47.996159</td>\n",
       "      <td>1390.170000</td>\n",
       "      <td>1367.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>BEXIMCO</td>\n",
       "      <td>62.7</td>\n",
       "      <td>61.3</td>\n",
       "      <td>62.7</td>\n",
       "      <td>62.7</td>\n",
       "      <td>17813467.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>87.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>...</td>\n",
       "      <td>58.0</td>\n",
       "      <td>104.317247</td>\n",
       "      <td>8.014383</td>\n",
       "      <td>59.832577</td>\n",
       "      <td>16.927423</td>\n",
       "      <td>85.918553</td>\n",
       "      <td>225.324494</td>\n",
       "      <td>84.006544</td>\n",
       "      <td>33.520000</td>\n",
       "      <td>28.351667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        tic    high     low    open   close      volume  day  \\\n",
       "0  2021-01-03  ALARABANK    22.1    21.5    22.1    21.9   1117376.0  6.0   \n",
       "0  2021-01-03   BANKASIA    18.1    17.8    18.0    18.0    286531.0  6.0   \n",
       "0  2021-01-03      BATBC  1254.6  1191.0  1191.0  1249.4    228763.0  6.0   \n",
       "0  2021-01-03  BERGERPBL  1470.0  1429.5  1429.5  1463.2     14184.0  6.0   \n",
       "0  2021-01-03    BEXIMCO    62.7    61.3    62.7    62.7  17813467.0  6.0   \n",
       "\n",
       "   short_resistance  short_support  ...  long_support  turbulence       macd  \\\n",
       "0              23.6           21.5  ...          20.1  104.317247   0.274896   \n",
       "0              19.6           17.8  ...          16.2  104.317247  -0.062325   \n",
       "0            1413.0         1184.0  ...         555.0  104.317247  29.420587   \n",
       "0            1576.9         1420.0  ...        1420.0  104.317247  20.824021   \n",
       "0              87.4           58.0  ...          58.0  104.317247   8.014383   \n",
       "\n",
       "       boll_ub      boll_lb     rsi_30      cci_30      dx_30  close_30_sma  \\\n",
       "0    23.318506    21.361494  57.821012  -33.282905  13.199225     22.146667   \n",
       "0    18.695997    17.844003  47.255202 -117.224880  19.980683     18.246667   \n",
       "0  1199.363592  1002.076408  71.029616  279.947144  64.397042   1079.650000   \n",
       "0  1490.759444  1347.870556  59.939370   97.314504  47.996159   1390.170000   \n",
       "0    59.832577    16.927423  85.918553  225.324494  84.006544     33.520000   \n",
       "\n",
       "   close_60_sma  \n",
       "0     20.186667  \n",
       "0     18.368333  \n",
       "0   1084.411667  \n",
       "0   1367.375000  \n",
       "0     28.351667  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_moedl = trained_a2c\n",
    "df_account_value_a2c, df_actions_a2c = DRLAgent.DRL_prediction(\n",
    "    model=trained_moedl,\n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "trained_moedl = trained_ddpg\n",
    "df_account_value_ddpg, df_actions_ddpg = DRLAgent.DRL_prediction(\n",
    "    model=trained_moedl,\n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_moedl = trained_ppo\n",
    "df_account_value_ppo, df_actions_ppo = DRLAgent.DRL_prediction(\n",
    "    model=trained_moedl,\n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_moedl = trained_td3\n",
    "df_account_value_td3, df_actions_td3 = DRLAgent.DRL_prediction(\n",
    "    model=trained_moedl,\n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_moedl = trained_sac\n",
    "df_account_value_sac, df_actions_sac = DRLAgent.DRL_prediction(\n",
    "    model=trained_moedl,\n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='7'></a>\n",
    "# Part 6.5: Mean Variance Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-d5231a90-c950-430a-b3fc-c5a2774382e2\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>1STBSRS</td>\n",
       "      <td>860.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>6THICB</td>\n",
       "      <td>581.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>8THICB</td>\n",
       "      <td>555.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>ABBANK</td>\n",
       "      <td>795.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>ACI</td>\n",
       "      <td>524.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d5231a90-c950-430a-b3fc-c5a2774382e2')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-d5231a90-c950-430a-b3fc-c5a2774382e2 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-d5231a90-c950-430a-b3fc-c5a2774382e2');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-c52fe350-8be2-4393-89b6-ea0a40b07864\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c52fe350-8be2-4393-89b6-ea0a40b07864')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-c52fe350-8be2-4393-89b6-ea0a40b07864 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "         date      tic   close\n",
       "0  2009-01-05  1STBSRS  860.50\n",
       "1  2009-01-05   6THICB  581.25\n",
       "2  2009-01-05   8THICB  555.75\n",
       "3  2009-01-05   ABBANK  795.25\n",
       "4  2009-01-05      ACI  524.80"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mvo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fst = mvo_df\n",
    "fst = fst.iloc[0*30:0*30+30, :]\n",
    "tic = fst['tic'].tolist()\n",
    "\n",
    "mvo = pd.DataFrame()\n",
    "\n",
    "for k in range(len(tic)):\n",
    "  mvo[tic[k]] = 0\n",
    "\n",
    "for i in range(mvo_df.shape[0]//29):\n",
    "  n = mvo_df\n",
    "  n = n.iloc[0*30:0*30+30, :]\n",
    "  date = n['date'][i*30]\n",
    "  mvo.loc[date] = n['close'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mvo.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import optimize\n",
    "from scipy.optimize import linprog\n",
    "\n",
    "#function obtains maximal return portfolio using linear programming\n",
    "\n",
    "def MaximizeReturns(MeanReturns, PortfolioSize):\n",
    "\n",
    "  #dependencies\n",
    "\n",
    "\n",
    "  c = (np.multiply(-1, MeanReturns))\n",
    "  A = np.ones([PortfolioSize,1]).T\n",
    "  b=[1]\n",
    "  res = linprog(c, A_ub = A, b_ub = b, bounds = (0,1), method = 'simplex')\n",
    "\n",
    "  return res\n",
    "\n",
    "def MinimizeRisk(CovarReturns, PortfolioSize):\n",
    "\n",
    "  def f(x, CovarReturns):\n",
    "    func = np.matmul(np.matmul(x, CovarReturns), x.T)\n",
    "    return func\n",
    "\n",
    "  def constraintEq(x):\n",
    "    A=np.ones(x.shape)\n",
    "    b=1\n",
    "    constraintVal = np.matmul(A,x.T)-b\n",
    "    return constraintVal\n",
    "\n",
    "  xinit=np.repeat(0.1, PortfolioSize)\n",
    "  cons = ({'type': 'eq', 'fun':constraintEq})\n",
    "  lb = 0\n",
    "  ub = 1\n",
    "  bnds = tuple([(lb,ub) for x in xinit])\n",
    "\n",
    "  opt = optimize.minimize (f, x0 = xinit, args = (CovarReturns),  bounds = bnds, \\\n",
    "                             constraints = cons, tol = 10**-3)\n",
    "\n",
    "  return opt\n",
    "\n",
    "def MinimizeRiskConstr(MeanReturns, CovarReturns, PortfolioSize, R):\n",
    "\n",
    "  def  f(x,CovarReturns):\n",
    "\n",
    "    func = np.matmul(np.matmul(x,CovarReturns ), x.T)\n",
    "    return func\n",
    "\n",
    "  def constraintEq(x):\n",
    "    AEq=np.ones(x.shape)\n",
    "    bEq=1\n",
    "    EqconstraintVal = np.matmul(AEq,x.T)-bEq\n",
    "    return EqconstraintVal\n",
    "\n",
    "  def constraintIneq(x, MeanReturns, R):\n",
    "    AIneq = np.array(MeanReturns)\n",
    "    bIneq = R\n",
    "    IneqconstraintVal = np.matmul(AIneq,x.T) - bIneq\n",
    "    return IneqconstraintVal\n",
    "\n",
    "\n",
    "  xinit=np.repeat(0.1, PortfolioSize)\n",
    "  cons = ({'type': 'eq', 'fun':constraintEq},\n",
    "          {'type':'ineq', 'fun':constraintIneq, 'args':(MeanReturns,R) })\n",
    "  lb = 0\n",
    "  ub = 1\n",
    "  bnds = tuple([(lb,ub) for x in xinit])\n",
    "\n",
    "  opt = optimize.minimize (f, args = (CovarReturns), method ='trust-constr',  \\\n",
    "                x0 = xinit,   bounds = bnds, constraints = cons, tol = 10**-3)\n",
    "\n",
    "  return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StockReturnsComputing(StockPrice, Rows, Columns):\n",
    "  import numpy as np\n",
    "  StockReturn = np.zeros([Rows-1, Columns])\n",
    "  for j in range(Columns):        # j: Assets\n",
    "    for i in range(Rows-1):     # i: Daily Prices\n",
    "      StockReturn[i,j]=((StockPrice[i+1, j]-StockPrice[i,j])/StockPrice[i,j])* 100\n",
    "\n",
    "  return StockReturn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate mean returns and variance-covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 117.2 , 3110.  ,  159.75,  219.  , 1005.  ,  236.  ,   65.  ,\n",
       "         510.  ,  419.5 ,  763.25,  119.5 , 1763.  , 2014.75, 3228.  ,\n",
       "         770.25,   40.  ,   22.  ,  843.5 ,  565.5 ,  532.5 ,  784.75,\n",
       "         504.7 ,  207.6 ,  354.5 ,   61.5 ,  298.25,   15.34,  423.  ,\n",
       "          68.25],\n",
       "       [1991.  , 3161.25,  744.  ,   41.25,   22.4 ,  839.5 ,  564.75,\n",
       "         531.25,  783.75,  505.5 ,  205.5 ,  362.  ,   62.2 ,  305.25,\n",
       "          15.56,  418.25,   68.75,  128.6 , 1102.75,   60.5 , 2323.25,\n",
       "         909.25,  469.5 ,  932.25,  281.1 ,  186.25,    8.8 ,  224.75,\n",
       "         298.8 ],\n",
       "       [  42.4 ,  207.  ,  149.5 ,  306.75,  100.  ,  115.1 , 3062.5 ,\n",
       "         163.5 ,  215.  , 1079.5 ,  228.  ,   66.5 ,  493.75,  415.75,\n",
       "         760.  ,  115.  , 1804.  , 1981.75, 3185.25,  735.25,   40.25,\n",
       "          21.3 ,  840.25,  567.75,  544.25,  776.  ,  505.5 ,  212.9 ,\n",
       "         346.25],\n",
       "       [ 502.  ,  407.75,  729.75,  114.9 , 1663.5 , 1907.75, 3106.75,\n",
       "         728.75,   40.75,   21.4 ,  833.75,  559.75,  538.  ,  775.  ,\n",
       "         504.  ,  209.7 ,  349.  ,   64.4 ,  300.5 ,   16.31,  422.  ,\n",
       "          69.5 ,  128.1 , 1166.  ,   61.5 , 2218.  ,  886.  ,  461.75,\n",
       "         919.  ],\n",
       "       [  81.25,  941.75,  289.5 ,   16.5 , 1922.75,   45.4 ,  199.75,\n",
       "         140.75,  295.5 ,  111.3 ,  113.6 , 3037.  ,  153.5 ,  206.25,\n",
       "        1037.5 ,  225.25,   65.5 ,  528.75,  406.75,  727.75,  114.5 ,\n",
       "        1769.5 , 1932.5 , 3111.25,  731.  ,   42.  ,   20.9 ,  844.25,\n",
       "         557.75],\n",
       "       [ 159.  ,  204.  , 1017.  ,  236.  ,   67.5 ,  512.  ,  406.  ,\n",
       "         738.75,  114.1 , 1782.5 , 1901.  , 3096.5 ,  722.75,   42.75,\n",
       "          20.7 ,  808.5 ,  541.25,  524.  ,  768.25,  509.4 ,  219.  ,\n",
       "         375.5 ,   62.6 ,  298.75,   15.77,  416.25,   66.75,  126.2 ,\n",
       "        1150.25],\n",
       "       [ 729.5 ,   41.5 ,   20.4 ,  782.75,  531.75,  491.75,  752.  ,\n",
       "         489.3 ,  212.4 ,  378.75,   59.2 ,  291.5 ,   14.96,  418.5 ,\n",
       "          67.5 ,  125.  , 1104.  ,   62.5 , 2101.75,  852.5 ,  466.75,\n",
       "         954.75,  267.8 ,  180.75,    9.  ,  215.25,  307.4 ,  174.25,\n",
       "         331.25],\n",
       "       [ 140.5 ,  290.75,  116.  ,  109.  , 2979.  ,  150.5 ,  206.75,\n",
       "         957.  ,  222.5 ,   63.75,  488.  ,  400.5 ,  739.5 ,  108.9 ,\n",
       "        1788.5 , 1868.25, 3104.  ,  727.25,   42.25,   19.9 ,  772.5 ,\n",
       "         529.5 ,  485.5 ,  745.25,  505.7 ,  211.8 ,  373.75,   59.8 ,\n",
       "         290.5 ],\n",
       "       [ 743.5 ,  109.4 , 1790.  , 1909.75, 3062.75,  735.75,   48.25,\n",
       "          22.5 ,  769.25,  524.5 ,  481.  ,  739.75,  513.8 ,  215.8 ,\n",
       "         413.5 ,   64.3 ,  292.75,   14.87,  418.25,   71.  ,  128.7 ,\n",
       "        1142.75,   67.5 , 2219.  ,  891.5 ,  483.  , 1092.5 ,  269.2 ,\n",
       "         185.5 ],\n",
       "       [ 285.75,   21.5 , 1872.25,   49.7 ,  182.75,  140.75,  282.75,\n",
       "         114.7 ,  108.7 , 2941.  ,  149.25,  205.  ,  941.75,  225.25,\n",
       "          71.  ,  484.  ,  396.25,  746.25,  109.3 , 1817.75, 1944.75,\n",
       "        3084.25,  736.  ,   47.25,   22.9 ,  798.75,  534.75,  513.  ,\n",
       "         720.5 ],\n",
       "       [ 957.25,  231.75,   72.25,  476.75,  392.25,  797.  ,  109.9 ,\n",
       "        2102.5 , 1938.  , 3048.  ,  753.5 ,   44.  ,   21.4 ,  776.25,\n",
       "         523.75,  514.  ,  707.75,  508.8 ,  210.  ,  478.25,   62.3 ,\n",
       "         296.5 ,   15.08,  405.75,   70.  ,  141.  , 1129.25,   66.75,\n",
       "        2110.75],\n",
       "       [  21.1 ,  790.75,  526.  ,  495.  ,  705.25,  514.5 ,  211.3 ,\n",
       "         482.25,   63.  ,  296.75,   15.05,  379.25,   70.  ,  143.  ,\n",
       "        1109.  ,   69.75, 2102.75,  860.25,  492.5 , 1005.  ,  276.1 ,\n",
       "         184.75,    9.8 ,  217.25,  316.8 ,  200.25,  315.25,  328.1 ,\n",
       "         209.7 ],\n",
       "       [ 213.  ,  214.25,  461.  , 1067.5 ,  195.5 , 1750.75,  126.  ,\n",
       "        1405.75,  467.5 ,   51.7 ,   64.5 ,   83.9 ,    6.  ,  798.25,\n",
       "         617.5 ,    7.  ,  691.25,  557.  ,  125.75,  359.25,   85.5 ,\n",
       "         997.  ,  280.75,   23.2 , 1954.25,   45.  ,  170.25,  142.25,\n",
       "         273.75]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Obtain optimal portfolio sets that maximize return and minimize risk\n",
    "\n",
    "#Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#input k-portfolio 1 dataset comprising 15 stocks\n",
    "# StockFileName = './DJIA_Apr112014_Apr112019_kpf1.csv'\n",
    "\n",
    "Rows = 1259  #excluding header\n",
    "Columns = 15  #excluding date\n",
    "portfolioSize = 29 #set portfolio size\n",
    "\n",
    "#read stock prices in a dataframe\n",
    "# df = pd.read_csv(StockFileName,  nrows= Rows)\n",
    "\n",
    "#extract asset labels\n",
    "# assetLabels = df.columns[1:Columns+1].tolist()\n",
    "# print(assetLabels)\n",
    "\n",
    "#extract asset prices\n",
    "# StockData = df.iloc[0:, 1:]\n",
    "StockData = mvo.head(mvo.shape[0]-336)\n",
    "TradeData = mvo.tail(336)\n",
    "# df.head()\n",
    "TradeData.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "negative dimensions are not allowed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "\u001b[0;32m<ipython-input-88-4ddca32e2e1c>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m      2\u001b[0m \u001b[0marStockPrices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStockData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      3\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mRows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marStockPrices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m----> 4\u001b[0;31m \u001b[0marReturns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStockReturnsComputing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marStockPrices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m<ipython-input-86-e17cf1f015c7>\u001b[0m in \u001b[0;36mStockReturnsComputing\u001b[0;34m(StockPrice, Rows, Columns)\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mStockReturnsComputing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStockPrice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      2\u001b[0m   \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mStockReturn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mRows\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mColumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m        \u001b[0;31m# j: Assets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRows\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0;31m# i: Daily Prices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;31mValueError\u001b[0m: negative dimensions are not allowed"
     ]
    }
   ],
   "source": [
    "#compute asset returns\n",
    "arStockPrices = np.asarray(StockData)\n",
    "[Rows, Cols]=arStockPrices.shape\n",
    "arReturns = StockReturnsComputing(arStockPrices, Rows, Cols)\n",
    "\n",
    "\n",
    "#compute mean returns and variance covariance matrix of returns\n",
    "meanReturns = np.mean(arReturns, axis = 0)\n",
    "covReturns = np.cov(arReturns, rowvar=False)\n",
    "\n",
    "#set precision for printing results\n",
    "np.set_printoptions(precision=3, suppress = True)\n",
    "\n",
    "#display mean returns and variance-covariance matrix of returns\n",
    "print('Mean returns of assets in k-portfolio 1\\n', meanReturns)\n",
    "print('Variance-Covariance matrix of returns\\n', covReturns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "\n",
    "ef_mean = EfficientFrontier(meanReturns, covReturns, weight_bounds=(0, 0.5))\n",
    "raw_weights_mean = ef_mean.max_sharpe()\n",
    "cleaned_weights_mean = ef_mean.clean_weights()\n",
    "mvo_weights = np.array([1000000 * cleaned_weights_mean[i] for i in range(29)])\n",
    "mvo_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StockData.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LastPrice = np.array([1/p for p in StockData.tail(1).to_numpy()[0]])\n",
    "Initial_Portfolio = np.multiply(mvo_weights, LastPrice)\n",
    "Initial_Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Portfolio_Assets = TradeData @ Initial_Portfolio\n",
    "MVO_result = pd.DataFrame(Portfolio_Assets, columns=[\"Mean Var\"])\n",
    "MVO_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6'></a>\n",
    "# Part 7: Backtesting Results\n",
    "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_a2c = df_account_value_a2c.set_index(df_account_value_a2c.columns[0])\n",
    "df_result_ddpg = df_account_value_ddpg.set_index(df_account_value_ddpg.columns[0])\n",
    "df_result_td3 = df_account_value_td3.set_index(df_account_value_td3.columns[0])\n",
    "df_result_ppo = df_account_value_ppo.set_index(df_account_value_ppo.columns[0])\n",
    "df_result_sac = df_account_value_sac.set_index(df_account_value_sac.columns[0])\n",
    "df_account_value_a2c.to_csv(\"df_account_value_a2c.csv\")\n",
    "#baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "df_dji_ = trade\n",
    "stats = backtest_stats(df_dji_, value_col_name = 'close')\n",
    "df_dji = pd.DataFrame()\n",
    "df_dji['date'] = df_account_value_a2c['date']\n",
    "df_dji['account_value'] = df_dji_['close'] / df_dji_['close'][0] * env_kwargs[\"initial_amount\"]\n",
    "df_dji.to_csv(\"df_dji.csv\")\n",
    "df_dji = df_dji.set_index(df_dji.columns[0])\n",
    "df_dji.to_csv(\"df_dji+.csv\")\n",
    "\n",
    "result = pd.merge(df_result_a2c, df_result_ddpg, left_index=True, right_index=True, suffixes=('_a2c', '_ddpg'))\n",
    "result = pd.merge(result, df_result_td3, left_index=True, right_index=True, suffixes=('', '_td3'))\n",
    "result = pd.merge(result, df_result_ppo, left_index=True, right_index=True, suffixes=('', '_ppo'))\n",
    "result = pd.merge(result, df_result_sac, left_index=True, right_index=True, suffixes=('', '_sac'))\n",
    "# result = pd.merge(result, MVO_result, left_index=True, right_index=True, suffixes=('', '_mvo'))\n",
    "result = pd.merge(result, df_dji, left_index=True, right_index=True, suffixes=('', '_dji'))\n",
    "result.columns = ['a2c', 'ddpg', 'td3', 'ppo', 'sac', 'dji']\n",
    "\n",
    "print(\"result: \", result)\n",
    "result.to_csv(\"result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "plt.figure();\n",
    "result.plot();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
